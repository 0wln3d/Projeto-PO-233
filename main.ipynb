{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e007a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "### Projeto da Disciplina de PO-233                                                                                        #\n",
    "### Título: Identificação de dados biométricos utilizando redes Wireless e aprendizado de máquina                          #\n",
    "### Alunos:                                                                                                                #\n",
    "###         Ágney Lopes Roth Ferraz                                                                                        #\n",
    "###\t        Alexandre Bellargus Silva da Costa                                                                             #\n",
    "###\t        Carlos Renato de Andrade Figueiredo                                                                            #\n",
    "###\t        Gioliano de Oliveira Braga                                                                                     #\n",
    "###\t        Paulo Ricardo Sousa Fonteles de Castro                                                                         #\n",
    "###\t        Wagner Comin Sonaglio                                                                                          #\n",
    "############################################################################################################################\n",
    "\n",
    "from time import time, strftime, gmtime\n",
    "inicio = time()\n",
    "print(\"Iniciando algoritmo...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca4b392",
   "metadata": {},
   "source": [
    "## -------------------- 01. Importação de Bibliotecas -------------------- \n",
    "\n",
    "Esta etapa organiza e importa todas as bibliotecas utilizadas ao longo do projeto. O código está estruturado em seções temáticas com comentários que facilitam a navegação e manutenção. Os grupos incluem:\n",
    "\n",
    "- **Sistema de Arquivos**: Operações com diretórios e caminhos (`os`, `shutil`, `pathlib`)\n",
    "- **Manipulação de Dados**: Leitura, organização e processamento vetorial/tabular com `numpy` e `pandas`\n",
    "- **Visualização**: Geração de gráficos com `matplotlib`, `seaborn` e visualização de árvores com `graphviz`\n",
    "- **Temporização**: Medição de tempo de execução com `timeit`\n",
    "- **Modelos de ML**: Diversos algoritmos supervisionados, como árvores, SVM, kNN, ensembles e redes neurais\n",
    "- **Utilidades de ML**: Pré-processamento, normalização, PCA e clonagem de modelos\n",
    "- **Validação**: Estratégias como hold-out, k-fold, Leave-One-Out e busca de hiperparâmetros (`GridSearchCV`)\n",
    "- **Métricas**: Avaliação de desempenho por acurácia, precisão, recall, F1-score, matriz de confusão e curva ROC\n",
    "- **Dados Sintéticos**: Geração de datasets artificiais para testes visuais\n",
    "- **Warnings**: Tratamento de alertas comuns como conversão e convergência\n",
    "- **Serialização**: Salvamento e carregamento de modelos com `joblib`\n",
    "\n",
    "Este bloco é essencial para garantir que todas as ferramentas necessárias estejam disponíveis antes da execução do pipeline de aprendizado de máquina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c07a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# Bibliotecas do Sistema e Manipulação de Arquivos\n",
    "# ===============================================================\n",
    "import os                            # Operações com sistema de arquivos\n",
    "import shutil                        # Operações para apagar arquivos e diretórios\n",
    "from pathlib import Path             # Caminhos multiplataforma\n",
    "\n",
    "# ===============================================================\n",
    "# Manipulação de Dados\n",
    "# ===============================================================\n",
    "import numpy as np                  # Operações numéricas e vetoriais\n",
    "import pandas as pd                 # Leitura e manipulação de dados tabulares\n",
    "import re                           # Necessário para limpar nomes de arquivos\n",
    "\n",
    "# ===============================================================\n",
    "# Visualização de Dados\n",
    "# ===============================================================\n",
    "import matplotlib.pyplot as plt      # Gráficos gerais\n",
    "import seaborn as sns                # Visualizações estatísticas\n",
    "from graphviz import Source          # Visualização de árvores (formato .dot)\n",
    "from sklearn.inspection import DecisionBoundaryDisplay  # Utilizado para visualizar as fronteiras de decisão dos classificadores em gráficos 2D\n",
    "\n",
    "# ===============================================================\n",
    "# Temporização\n",
    "# ===============================================================\n",
    "from timeit import default_timer as timer  # Cronômetro para medir tempo de execução\n",
    "\n",
    "# ===============================================================\n",
    "# Aprendizado de Máquina - Modelos\n",
    "# ===============================================================\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz    # Árvores de decisão\n",
    "from sklearn.neighbors import KNeighborsClassifier                   # kNN\n",
    "from sklearn.naive_bayes import GaussianNB                           # Naive Bayes\n",
    "from sklearn.svm import SVC, LinearSVC                               # Máquinas de Vetores de Suporte\n",
    "from sklearn.linear_model import SGDClassifier                       # Gradiente Estocástico\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier  # Ensemble\n",
    "from sklearn.neural_network import MLPClassifier                     # Redes Neurais\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis  # Análise discriminante\n",
    "\n",
    "# ===============================================================\n",
    "# Aprendizado de Máquina - Utilidades\n",
    "# ===============================================================\n",
    "from sklearn.base import clone                                       # Clonagem de modelos\n",
    "from sklearn.preprocessing import StandardScaler                     # Normalização de atributos\n",
    "from sklearn.decomposition import PCA                                # Redução de dimensionalidade\n",
    "\n",
    "# ===============================================================\n",
    "# Validação e Seleção de Modelos\n",
    "# ===============================================================\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,             # Separação treino/validação\n",
    "    cross_val_score,              # Validação cruzada simples\n",
    "    StratifiedKFold,              # Validação estratificada\n",
    "    GridSearchCV,                 # Busca em grade de hiperparâmetros\n",
    "    LeaveOneOut                   # Validação Leave-One-Out\n",
    ")\n",
    "\n",
    "# ===============================================================\n",
    "# Métricas de Avaliação\n",
    "# ===============================================================\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,            # Métricas principais\n",
    "    confusion_matrix, classification_report,                            # Relatórios e matrizes\n",
    "    roc_curve, auc                                                      # Curvas ROC e área sob a curva\n",
    ")\n",
    "\n",
    "# ===============================================================\n",
    "# Geração de Dados Sintéticos\n",
    "# ===============================================================\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification  # Bases de teste\n",
    "\n",
    "# ===============================================================\n",
    "# Tratamento de Warnings\n",
    "# ===============================================================\n",
    "import warnings                        # Controle de avisos\n",
    "from sklearn.exceptions import (\n",
    "    DataConversionWarning,             # Conversão de tipos\n",
    "    ConvergenceWarning                 # Convergência de modelos (MLP, etc.)\n",
    ")\n",
    "\n",
    "# ===============================================================\n",
    "# Serialização de Modelos\n",
    "# ===============================================================\n",
    "import joblib                          # Salvamento e carregamento de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39c1cd0",
   "metadata": {},
   "source": [
    "## -------------------- 02. Leitura dos Arquivos Disponíveis -------------------- \n",
    "\n",
    "Esta etapa realiza a leitura da pasta `/db/` em busca de arquivos `.csv`, que contêm os dados capturados do Channel State Information (CSI). Esses arquivos são listados e exibidos no terminal, para que o usuário escolha qual utilizar nas etapas seguintes de pré-processamento e modelagem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d877472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o caminho da pasta onde estão os arquivos .csv\n",
    "db_path = Path('./db')\n",
    "\n",
    "# Lista todos os arquivos com extensão .csv no diretório /db/\n",
    "arquivos_db = list(db_path.glob('*.csv'))\n",
    "\n",
    "# Imprime uma mensagem informativa no terminal\n",
    "print(\"Arquivos csv disponíveis na pasta /db/:\")\n",
    "\n",
    "# Percorre cada arquivo encontrado na lista\n",
    "for arquivo in arquivos_db:\n",
    "    # Imprime apenas o nome do arquivo (sem o caminho completo)\n",
    "    print(\"-\", arquivo.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17cbc41",
   "metadata": {},
   "source": [
    "## -------------------- 03. Definição dos Arquivos de Dados e Carregamento Inicial -------------------- \n",
    "\n",
    "Nesta etapa são definidos os caminhos para os arquivos `.csv` que representam diferentes cenários do experimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a54c783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o diretório base onde estão localizados os arquivos .csv\n",
    "db_dir = Path('db')\n",
    "\n",
    "# Define o caminho completo do arquivo principal de treino e validação\n",
    "arquivo_treino_validacao = db_dir / 'db_3200.csv'\n",
    "\n",
    "# Define o caminho do arquivo usado para teste final com dados nunca vistos\n",
    "arquivo_teste_real = db_dir / 'db_800.csv'\n",
    "\n",
    "# Define o caminho do arquivo com 271 portadoras\n",
    "arquivo_pca_271_portadoras = db_dir / 'db_400.csv'\n",
    "\n",
    "# Carrega os dados do arquivo principal em um DataFrame usando pandas\n",
    "df = pd.read_csv(arquivo_treino_validacao)\n",
    "\n",
    "# Exibe as primeiras linhas do DataFrame para verificação inicial\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2e1df8",
   "metadata": {},
   "source": [
    "## -------------------- 04. Preparação do Diretório de Resultados --------------------\n",
    "\n",
    "Esta etapa garante que o diretório `results/`, onde serão salvos todos os gráficos, matrizes e relatórios do experimento, esteja limpo e pronto para uso. \n",
    "A pasta é criada caso não exista e todos os arquivos e subpastas antigos dentro dela são removidos. Isso evita acúmulo de resultados de execuções anteriores e garante que apenas os dados atualizados estejam disponíveis ao final da execução dos experimentos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f803d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o caminho da pasta onde os resultados serão salvos\n",
    "results_path = Path(\"results\")\n",
    "\n",
    "# Cria a pasta 'results' e todas as subpastas necessárias, caso ainda não existam\n",
    "results_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Percorre todos os itens (arquivos e subpastas) dentro da pasta 'results'\n",
    "for item in results_path.iterdir():\n",
    "    \n",
    "    # Se o item for um arquivo, remove com unlink()\n",
    "    if item.is_file():\n",
    "        item.unlink()\n",
    "    \n",
    "    # Se o item for uma subpasta, remove com rmtree()\n",
    "    elif item.is_dir():\n",
    "        shutil.rmtree(item)\n",
    "\n",
    "# Informa no terminal que a pasta está pronta para uso\n",
    "print(\"Diretório 'results' limpo e pronto para uso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fadc70b",
   "metadata": {},
   "source": [
    "## -------------------- 05. Pré-processamento: Conversão de Gênero para Valores Numéricos --------------------\n",
    "\n",
    "Antes de aplicar algoritmos de aprendizado de máquina, é necessário que os dados estejam em um formato numérico. Esta função realiza a conversão da coluna `gender` — originalmente contendo valores categóricos `'f'` (female) e `'m'` (male) — para valores numéricos `0` e `1`, respectivamente.\n",
    "Essa conversão facilita o treinamento dos modelos, que esperam entradas numéricas como rótulos para classificação. A função modifica a coluna diretamente no DataFrame e retorna o novo conjunto tratado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946fdbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define uma função para converter a coluna 'gender' de categórico para numérico\n",
    "def convert_gender_to_numeric(df):\n",
    "    \n",
    "    # Substitui os valores 'f' por 0 e 'm' por 1 na coluna 'gender'\n",
    "    df['gender'] = df['gender'].replace({'f': 0, 'm': 1})\n",
    "    \n",
    "    # Retorna o DataFrame com a coluna 'gender' convertida\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404dd207",
   "metadata": {},
   "source": [
    "## -------------------- 06. PCA com Visualização Bidimensional (8 e 271 subportadoras) --------------------\n",
    "\n",
    "Esta etapa realiza uma **análise exploratória visual** por meio da técnica de **PCA (Principal Component Analysis)**. O objetivo é observar se existe separação visual entre homens e mulheres com base nas subportadoras do CSI.\n",
    "\n",
    "Duas versões do conjunto de dados são analisadas:\n",
    "- **271 subportadoras**: base `db_400.csv`, com dimensionalidade reduzida via PCA após pré-processamento.\n",
    "- **8 subportadoras**: base original `db_3200.csv`, com menos atributos por amostra.\n",
    "\n",
    "Para ambas, aplica-se:\n",
    "- Normalização com média zero e variância um (usando `StandardScaler`)\n",
    "- Redução para 2 componentes principais (`PCA(n_components=2)`)\n",
    "- Geração de gráficos de dispersão com `Seaborn`, destacando as classes por cor.\n",
    "\n",
    "As imagens são salvas nos arquivos:\n",
    "- `results/pca_271p.png`\n",
    "- `results/pca_8p.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad18d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega os dados da base com 271 subportadoras (após PCA externo ou seleção)\n",
    "df = pd.read_csv(arquivo_pca_271_portadoras)\n",
    "# Separa a variável alvo: 0 para mulher, 1 para homem\n",
    "y = df.iloc[:, 0]\n",
    "# Separa as colunas de atributos (subportadoras)\n",
    "X = df.iloc[:, 1:]\n",
    "# Cria o objeto de normalização (média zero, variância 1)\n",
    "scaler = StandardScaler()\n",
    "# Aplica normalização aos atributos\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# Converte os rótulos numéricos para texto (para legenda do gráfico)\n",
    "labels = y.map({0: 'Men', 1: 'Women'})\n",
    "# Cria um objeto PCA para reduzir para 2 componentes principais\n",
    "pca = PCA(n_components=2)\n",
    "# Aplica o PCA sobre os dados normalizados\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "# Cria uma nova figura com tamanho 8x6\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Gera gráfico de dispersão com cores diferentes para cada gênero\n",
    "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1],\n",
    "                hue=y.map({0: 'Women', 1: 'Men'}), palette='Set1')\n",
    "# Define o título do gráfico\n",
    "plt.title('PCA Dispersion by Gender - 271 subcarriers')\n",
    "# Rótulo do eixo X\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "# Rótulo do eixo Y\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "# Exibe legenda\n",
    "plt.legend()\n",
    "# Exibe grade no fundo do gráfico\n",
    "plt.grid(True)\n",
    "# Ajusta layout para evitar cortes nos elementos do gráfico\n",
    "plt.tight_layout()\n",
    "# Salva a imagem gerada no diretório de resultados\n",
    "plt.savefig(\"results/pca_271p.png\", dpi=300)\n",
    "# Exibe caminho salvo no terminal\n",
    "print(\"PCA 271p: results/pca_271p.png\")\n",
    "# Fecha a figura (boa prática para liberar memória)\n",
    "plt.close()\n",
    "\n",
    "# Carrega os dados da base com 8 subportadoras (original, sem redução externa)\n",
    "df = pd.read_csv(arquivo_treino_validacao)\n",
    "# Separa a variável alvo: 0 para mulher, 1 para homem\n",
    "y = df.iloc[:, 0]\n",
    "# Separa os atributos (subportadoras)\n",
    "X = df.iloc[:, 1:]\n",
    "# Cria o objeto de normalização\n",
    "scaler = StandardScaler()\n",
    "# Aplica a normalização\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# Converte rótulos numéricos para texto para uso no gráfico\n",
    "labels = y.map({0: 'Men', 1: 'Women'})\n",
    "# Cria o objeto PCA com 2 componentes\n",
    "pca = PCA(n_components=2)\n",
    "# Reduz os dados para 2D com PCA\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "# Cria uma nova figura com tamanho 8x6\n",
    "plt.figure(figsize=(8, 6))\n",
    "# Gera gráfico de dispersão colorido por classe\n",
    "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1],\n",
    "                hue=y.map({0: 'Women', 1: 'Men'}), palette='Set1')\n",
    "# Título do gráfico\n",
    "plt.title('PCA Dispersion by Gender - 8 subcarriers')\n",
    "# Rótulo do eixo X\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "# Rótulo do eixo Y\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "# Exibe legenda\n",
    "plt.legend()\n",
    "# Ativa a grade\n",
    "plt.grid(True)\n",
    "# Ajusta layout para evitar cortes\n",
    "plt.tight_layout()\n",
    "# Salva o gráfico no diretório de resultados\n",
    "plt.savefig(\"results/pca_8p.png\", dpi=300)\n",
    "# Exibe caminho salvo no terminal\n",
    "print(\"PCA 8p: results/pca_8p.png\")\n",
    "# Fecha a figura para liberar memória\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65acff7d",
   "metadata": {},
   "source": [
    "## -------------------- 07. Visualização da Dispersão entre Portadoras (Pairplot) -------------------- \n",
    "\n",
    "Nesta etapa, é gerado um gráfico do tipo **pairplot**, que permite visualizar as relações entre diferentes subportadoras do CSI, separadas por gênero. O gráfico mostra como as distribuições e correlações entre os sinais das portadoras podem indicar diferenças entre homens e mulheres.\n",
    "\n",
    "A base utilizada é o de treino e validação, com foco nas seguintes 8 portadoras:\n",
    "- `rpi1_sc-118`, `rpi1_sc-111`, `rpi1_sc2`, `rpi1_sc32`\n",
    "- `rpi1_sc67`, `rpi1_sc106`, `rpi1_sc120`, `rpi1_sc121`\n",
    "\n",
    "O gráfico gerado é salvo no arquivo `results/pair_plot.png` e será usado para análise visual de separabilidade entre as classes antes do treinamento dos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a62f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lê o banco de dados de treino/teste\n",
    "df = pd.read_csv(arquivo_treino_validacao)\n",
    "\n",
    "# Cria o diretório 'results' caso ainda não exista\n",
    "Path(\"results\").mkdir(exist_ok=True)\n",
    "\n",
    "# Define os nomes das 8 subportadoras a serem usadas no gráfico\n",
    "portadoras = ['rpi1_sc-118', 'rpi1_sc-111', 'rpi1_sc2', 'rpi1_sc32',\n",
    "              'rpi1_sc67', 'rpi1_sc106', 'rpi1_sc120', 'rpi1_sc121']\n",
    "\n",
    "# Cria um novo DataFrame contendo apenas as subportadoras selecionadas e a coluna de gênero\n",
    "df_plot = df[portadoras + ['gender']].copy()\n",
    "\n",
    "# Converte os rótulos 0 e 1 para 'Women' e 'Men' para fins de visualização\n",
    "df_plot['gender'] = df_plot['gender'].map({0: 'Women', 1: 'Men'})\n",
    "\n",
    "# Cria um gráfico de dispersão múltipla entre todas as subportadoras\n",
    "plot = sns.pairplot(df_plot, hue='gender', palette='Set1', corner=True)\n",
    "\n",
    "# Define o título do gráfico acima da figura\n",
    "plt.suptitle(\"Carrier Dispersion by Gender\", y=1.02)\n",
    "\n",
    "# Salva o gráfico em alta resolução no diretório de resultados\n",
    "plot.savefig(\"results/pair_plot.png\", dpi=300)\n",
    "\n",
    "# Fecha a figura para liberar memória\n",
    "plt.close()\n",
    "\n",
    "# Exibe uma mensagem indicando o caminho do arquivo salvo\n",
    "print(\"Pairplot salvo em: results/pair_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa29cdd",
   "metadata": {},
   "source": [
    "## -------------------- 08. Função de Geração do Boxplot Melhorado --------------------\n",
    "\n",
    "Esta função é utilizada para **visualizar graficamente o desempenho dos algoritmos** de aprendizado de máquina usando boxplots. Ela recebe um dicionário contendo listas de scores (ex: acurácias) de diferentes classificadores e gera um gráfico comparativo.\n",
    "\n",
    "Funcionalidades incluídas:\n",
    "- Conversão de entradas não-string para o eixo Y, se necessário.\n",
    "- Remoção de valores `NaN` das listas para evitar falhas no plot.\n",
    "- Salvamento do gráfico em alta definição no local especificado.\n",
    "\n",
    "Este tipo de gráfico ajuda a identificar visualmente a **dispersão dos resultados** e a **robustez** de cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47edcbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define uma função para gerar e salvar um gráfico boxplot com os resultados dos modelos\n",
    "def plot_boxplot(result: dict, alg_name, boxplot_file, y_label_text=\"Score\", titulo=\"Boxplot de Resultados\"):\n",
    "    \n",
    "    # Converte o dicionário de resultados em DataFrame (não é usado diretamente no plot, mas pode ser útil)\n",
    "    df_result = pd.DataFrame.from_dict(result)\n",
    "\n",
    "    # Verifica se o rótulo do eixo Y é uma string; se não for, converte\n",
    "    if not isinstance(y_label_text, str):\n",
    "        print(f\"Warning: y_label_text era {type(y_label_text)}. Convertendo.\")\n",
    "        y_label_text = str(y_label_text)\n",
    "\n",
    "    # Define o estilo padrão do matplotlib\n",
    "    plt.style.use('default')\n",
    "\n",
    "    # Define o tamanho da figura do boxplot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Remove valores NaN das listas de resultados para evitar erro no gráfico\n",
    "    cleaned = [pd.Series(v).dropna() for v in result.values()]\n",
    "\n",
    "    # Gera o gráfico boxplot usando os dados limpos\n",
    "    plt.boxplot(cleaned, tick_labels=list(result.keys()))\n",
    "\n",
    "    # Define o título do gráfico\n",
    "    plt.title(titulo)\n",
    "\n",
    "    # Define o rótulo do eixo Y\n",
    "    plt.ylabel(y_label_text)\n",
    "\n",
    "    # Rotaciona os rótulos do eixo X para melhor visualização\n",
    "    plt.xticks(rotation=15)\n",
    "\n",
    "    # Adiciona grade horizontal ao gráfico\n",
    "    plt.grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "    # Ajusta automaticamente os elementos do layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Salva o gráfico no arquivo especificado com alta resolução\n",
    "    plt.savefig(boxplot_file, dpi=300)\n",
    "\n",
    "    # Fecha o gráfico para liberar memória\n",
    "    plt.close()\n",
    "\n",
    "    # Exibe mensagem informando onde o gráfico foi salvo\n",
    "    print(f\"Boxplot salvo em: {boxplot_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabe3bad",
   "metadata": {},
   "source": [
    "## -------------------- 09. Avaliação com Hold-Out (com 20% de validação) --------------------\n",
    "\n",
    "Este bloco realiza a **validação hold-out**, separando 80% dos dados para treino e 20% para validação. Ele executa os seguintes passos:\n",
    "\n",
    "- Criação e limpeza do diretório `results/hold-out`.\n",
    "- Divisão dos dados em treino e validação com estratificação para manter a proporção de classes.\n",
    "- Treinamento de seis modelos diferentes:\n",
    "  - kNN (3 vizinhos)\n",
    "  - Árvore de Decisão (profundidade 5)\n",
    "  - Árvore Grande (sem limitação)\n",
    "  - Naive Bayes\n",
    "  - SVM Linear (C=0.025)\n",
    "  - SVM com kernel RBF (γ=2, C=1)\n",
    "\n",
    "Para cada modelo:\n",
    "- Realiza o treino e predição.\n",
    "- Calcula acurácia e gera relatório com precisão, recall e F1-score.\n",
    "- Salva a matriz de confusão como imagem.\n",
    "- Mantém registro da melhor acurácia encontrada.\n",
    "\n",
    "Ao final:\n",
    "- Gera um boxplot comparando as acurácias dos modelos.\n",
    "- Gera um barplot com os valores individuais.\n",
    "- Salva o nome do melhor modelo e a acurácia final em `.txt`.\n",
    "- Serializa o modelo vencedor com `joblib` para uso futuro.\n",
    "\n",
    "Todos os resultados são armazenados na pasta `results/hold-out/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae8bd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lê o banco de dados de treino/teste\n",
    "df = pd.read_csv(arquivo_treino_validacao)\n",
    "\n",
    "# Garante que o diretório de resultados para Hold-Out exista\n",
    "output_dir = Path(\"results/hold-out\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Limpa todos os arquivos e pastas dentro do diretório de resultados\n",
    "for item in output_dir.iterdir():\n",
    "    if item.is_file():\n",
    "        item.unlink()\n",
    "    elif item.is_dir():\n",
    "        shutil.rmtree(item)\n",
    "\n",
    "# Define o caminho do arquivo de relatório\n",
    "relatorio_path = Path(\"results/hold-out/relatorio.txt\")\n",
    "\n",
    "# Separa os atributos (X) e os rótulos (y)\n",
    "X = df.drop('gender', axis=1)\n",
    "y = df['gender']\n",
    "\n",
    "# Divide o conjunto em treino (80%) e validação (20%) com estratificação\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Exibe as dimensões dos conjuntos gerados\n",
    "print(f\"Treino: {X_train.shape}, Validação: {X_val.shape}\")\n",
    "\n",
    "# Define os modelos que serão testados\n",
    "modelos = {\n",
    "    \"kNN\": KNeighborsClassifier(3),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=5),\n",
    "    \"Big Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"SVM Linear\": SVC(kernel=\"linear\", C=0.025, probability=True),\n",
    "    \"SVM RBF\": SVC(gamma=2, C=1, probability=True)\n",
    "}\n",
    "\n",
    "# Inicializa os dicionários para armazenar os resultados\n",
    "modelos_treinados = {}\n",
    "acuracias = {}\n",
    "resultados_val = {}\n",
    "relatorio_final = \"\"\n",
    "melhor_acc = 0\n",
    "melhor_nome = \"\"\n",
    "melhor_modelo = None\n",
    "\n",
    "# Abre o arquivo de relatório para escrita\n",
    "with open(relatorio_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    \n",
    "    # Escreve o cabeçalho do relatório\n",
    "    f.write(\"Relatório Hold-Out (20% de validação):\\n\\n\")\n",
    "    \n",
    "    # Itera sobre os modelos definidos\n",
    "    for nome, modelo in modelos.items():\n",
    "        \n",
    "        # Clona o modelo para garantir independência entre execuções\n",
    "        clf = clone(modelo)\n",
    "        \n",
    "        # Treina o modelo com os dados de treino\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # Salva o modelo treinado\n",
    "        modelos_treinados[nome] = clf        \n",
    "\n",
    "        # Realiza a predição sobre os dados de validação\n",
    "        y_val_pred = clf.predict(X_val)\n",
    "        \n",
    "        # Calcula a acurácia do modelo\n",
    "        acc = accuracy_score(y_val, y_val_pred)\n",
    "        \n",
    "        # Armazena a acurácia\n",
    "        acuracias[nome] = acc\n",
    "        resultados_val[nome] = [acc]\n",
    "\n",
    "        # Gera o relatório detalhado\n",
    "        relatorio = classification_report(\n",
    "            y_val, y_val_pred, target_names=[\"Women\", \"Men\"], zero_division=0, digits=4\n",
    "        )\n",
    "        \n",
    "        # Escreve os resultados no relatório em arquivo\n",
    "        f.write(f\"Modelo: {nome}\\n\")\n",
    "        f.write(relatorio)\n",
    "        f.write(\"\\n\" + \"-\" * 60 + \"\\n\")\n",
    "        \n",
    "        # Também imprime no terminal para feedback visual\n",
    "        print(f\"\\nModelo: {nome}\")\n",
    "        print(relatorio)\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        # Gera a matriz de confusão para o modelo atual\n",
    "        cm = confusion_matrix(y_val, y_val_pred, labels=[0, 1])\n",
    "        \n",
    "        # Cria figura para o heatmap\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        \n",
    "        # Cria gráfico da matriz de confusão\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=[\"Women\", \"Men\"], yticklabels=[\"Women\", \"Men\"])\n",
    "        \n",
    "        # Define os rótulos e título do gráfico\n",
    "        plt.xlabel(\"Classe Predita\")\n",
    "        plt.ylabel(\"Classe Real\")\n",
    "        plt.title(f\"Matriz de Confusão - {nome}\")\n",
    "        \n",
    "        # Ajusta layout\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Salva a imagem gerada\n",
    "        plt.savefig(f\"results/hold-out/{nome}_matriz_confusao.png\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # Atualiza o melhor modelo, se aplicável\n",
    "        if acc > melhor_acc:\n",
    "            melhor_acc = acc\n",
    "            melhor_nome = nome\n",
    "            melhor_modelo = clf\n",
    "\n",
    "# Gera gráfico boxplot com as acurácias\n",
    "plot_boxplot(\n",
    "    result=resultados_val,\n",
    "    alg_name=\"Todos\",\n",
    "    boxplot_file=\"results/hold-out/boxplot.png\",\n",
    "    y_label_text=\"Acurácia\",\n",
    "    titulo=\"Boxplot - Hold-Out (20% Validação)\"\n",
    ")\n",
    "\n",
    "# Cria DataFrame com acurácias para barplot\n",
    "df_plot = pd.DataFrame({\n",
    "    \"Modelo\": list(acuracias.keys()),\n",
    "    \"Acurácia\": list(acuracias.values())\n",
    "})\n",
    "\n",
    "# Cria figura do barplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Modelo\", y=\"Acurácia\", data=df_plot)\n",
    "\n",
    "# Define limites e títulos do gráfico\n",
    "plt.ylim(0, 1.05)\n",
    "plt.title(\"Acurácia dos Modelos - Hold-Out (20%)\")\n",
    "plt.ylabel(\"Acurácia\")\n",
    "plt.xlabel(\"Modelos\")\n",
    "\n",
    "# Adiciona grade horizontal\n",
    "plt.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "plt.xticks(rotation=15)\n",
    "\n",
    "# Ajusta o layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Salva o gráfico\n",
    "plt.savefig(\"results/hold-out/barplot.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Exibe mensagem no terminal\n",
    "print(\"Barplot salvo em: results/hold-out/barplot.png\")\n",
    "\n",
    "# Salva o nome e acurácia do melhor modelo em .txt\n",
    "with open(\"results/hold-out/melhor_modelo.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"Melhor modelo: {melhor_nome}\\nAcurácia: {melhor_acc:.4f}\")\n",
    "\n",
    "# Salva o objeto do melhor modelo usando joblib\n",
    "joblib.dump(melhor_modelo, \"results/hold-out/melhor_modelo.pkl\")\n",
    "\n",
    "# Mensagens finais de conclusão\n",
    "print(\"\\nAnálise concluída com sucesso!\")\n",
    "print(f\"\\nMelhor modelo: {melhor_nome} (Acurácia: {melhor_acc:.4f})\")\n",
    "print(\"Resultados salvos em: results/hold-out/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9d7d36",
   "metadata": {},
   "source": [
    "## -------------------- 10. Validação com Leave-One-Out (LOO) --------------------\n",
    "\n",
    "Este bloco realiza uma avaliação completa com a técnica **Leave-One-Out (LOO)**, onde cada amostra do conjunto é usada uma vez como teste e o restante como treino.\n",
    "\n",
    "**Passos executados:**\n",
    "\n",
    "1. Carrega o dataset de treino/validação.\n",
    "2. Limpa o diretório `results/leave-one-out`.\n",
    "3. Define seis classificadores:\n",
    "   - Árvores (Decision Tree com e sem limitação de profundidade - Big Tree)\n",
    "   - kNN\n",
    "   - Naive Bayes\n",
    "   - SVM Linear\n",
    "   - SVM RBF (via `SVC`)\n",
    "4. Para cada modelo:\n",
    "   - Executa o LOO.\n",
    "   - Agrupa acurácias em blocos de 100.\n",
    "   - Gera relatório e matriz de confusão.\n",
    "   - Atualiza o melhor modelo com base na acurácia média.\n",
    "5. Ao final:\n",
    "   - Gera gráficos (`boxplot.png`, `barplot.png`).\n",
    "   - Treina o melhor modelo com todos os dados.\n",
    "   - Salva o modelo (`melhor_modelo.pkl`) e sua acurácia (`melhor_modelo.txt`).\n",
    "\n",
    "Os resultados são salvos em `results/leave-one-out/`. Essa validação é mais exaustiva e sensível a overfitting, ideal quando se busca precisão máxima com poucos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6c6161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lê o arquivo CSV com os dados\n",
    "df = pd.read_csv(arquivo_treino_validacao)\n",
    "\n",
    "# Cria o diretório de saída para resultados se não existir\n",
    "output_dir = Path(\"results/leave-one-out\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Limpa arquivos e subpastas antigas do diretório de resultados\n",
    "for item in output_dir.iterdir():\n",
    "    if item.is_file():\n",
    "        item.unlink()  # Remove arquivos\n",
    "    elif item.is_dir():\n",
    "        shutil.rmtree(item)  # Remove diretórios\n",
    "\n",
    "# Define estilo de visualização para gráficos\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Define o tamanho padrão dos gráficos\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "# Define a precisão de exibição de números no pandas\n",
    "pd.set_option('display.precision', 3)\n",
    "\n",
    "# Define os modelos que serão avaliados\n",
    "algorithms = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=3, random_state=42),\n",
    "    \"Big Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"kNN\": KNeighborsClassifier(n_neighbors=3, n_jobs=-1),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"SVM Linear\": LinearSVC(C=0.1, max_iter=10000, random_state=42),\n",
    "    \"SVM RBF\": SVC(gamma='scale', C=1, probability=False, cache_size=500, random_state=42)\n",
    "}\n",
    "\n",
    "# Função que agrupa listas de acurácias em blocos (para visualização mais clara do Boxplot)\n",
    "def agrupa_media(accs, step=100):\n",
    "    return [np.mean(accs[i:i+step]) for i in range(0, len(accs), step)]\n",
    "\n",
    "# Avalia o desempenho de um modelo usando Leave-One-Out\n",
    "# Retorna lista de acurácias, rótulos reais e previstos\n",
    "\n",
    "def evaluate_model_fast(df, model_name):\n",
    "    X = df.drop(columns=[\"gender\"]).values  # Atributos\n",
    "    y = df[\"gender\"].values  # Classe alvo\n",
    "    model = clone(algorithms[model_name])  # Clona o modelo da lista\n",
    "    scaler = StandardScaler()  # Normalizador padrão\n",
    "    accuracies = []  # Lista para armazenar acurácias\n",
    "    y_true, y_pred = [], []  # Rótulos reais e previstos\n",
    "\n",
    "    # Para cada divisão leave-one-out\n",
    "    for train_idx, test_idx in LeaveOneOut().split(X):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Normaliza com base no treino\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Treina o modelo\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Faz a predição\n",
    "        pred = model.predict(X_test)\n",
    "\n",
    "        # Armazena resultados\n",
    "        accuracies.append(accuracy_score(y_test, pred))\n",
    "        y_true.append(y_test[0])\n",
    "        y_pred.append(pred[0])\n",
    "\n",
    "    return np.array(accuracies), model_name, y_true, y_pred\n",
    "\n",
    "# Gera gráfico boxplot a partir dos resultados\n",
    "\n",
    "def plot_boxplot(result: dict, boxplot_file, y_label_text=\"Score\", titulo=\"Boxplot de Resultados\"):\n",
    "    plt.style.use('default')  # Estilo padrão\n",
    "    plt.figure(figsize=(10, 6))  # Tamanho do gráfico\n",
    "    cleaned = [pd.Series(v).dropna() for v in result.values()]  # Remove NaNs\n",
    "    plt.boxplot(cleaned, tick_labels=list(result.keys()))  # Gera o boxplot\n",
    "    plt.title(titulo)\n",
    "    plt.ylabel(y_label_text)\n",
    "    plt.xticks(rotation=15)\n",
    "    plt.grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(boxplot_file, dpi=300)  # Salva como PNG\n",
    "    plt.close()\n",
    "    print(f\"Boxplot salvo em: {boxplot_file}\")\n",
    "\n",
    "# Função principal para rodar a análise LOO completa\n",
    "\n",
    "def run_analysis(df):\n",
    "    resultados = {}  # Guarda todas as acurácias\n",
    "    resultados_boxplot = {}  # Guarda resultados em blocos para gráfico\n",
    "    melhor_acc = 0  # Armazena a melhor acurácia\n",
    "    melhor_modelo_nome = \"\"  # Nome do melhor modelo\n",
    "    relatorio_path = output_dir / \"relatorio.txt\"  # Caminho do relatório\n",
    "\n",
    "    with open(relatorio_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Relatório Leave-One-Out:\\n\\n\")\n",
    "\n",
    "        for name in algorithms:\n",
    "            # Avalia o modelo\n",
    "            accs, _, y_true, y_pred = evaluate_model_fast(df, name)\n",
    "            resultados[name] = accs\n",
    "            resultados_boxplot[name] = agrupa_media(accs, step=100)\n",
    "\n",
    "            # Calcula a média das acurácias\n",
    "            media = np.mean(accs)\n",
    "            if media > melhor_acc:\n",
    "                melhor_acc = media\n",
    "                melhor_modelo_nome = name\n",
    "\n",
    "            # Gera relatório\n",
    "            relatorio = classification_report(y_true, y_pred, target_names=[\"Women\", \"Men\"], digits=4, zero_division=0)\n",
    "            f.write(f\"Modelo: {name}\\n{relatorio}\\n\" + \"-\" * 60 + \"\\n\")\n",
    "\n",
    "            print(f\"\\nModelo: {name}\")\n",
    "            print(relatorio)\n",
    "            print(\"-\" * 60)\n",
    "\n",
    "            # Gera matriz de confusão\n",
    "            cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "            plt.figure(figsize=(6, 5))\n",
    "            sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                        xticklabels=[\"Women\", \"Men\"], yticklabels=[\"Women\", \"Men\"])\n",
    "            plt.xlabel(\"Classe Predita\")\n",
    "            plt.ylabel(\"Classe Real\")\n",
    "            plt.title(f\"Matriz de Confusão - {name}\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(output_dir / f\"{name}_matriz_confusao.png\", dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "    # Gera boxplot final\n",
    "    plot_boxplot(\n",
    "        result=resultados_boxplot,\n",
    "        boxplot_file=output_dir / \"boxplot.png\",\n",
    "        y_label_text=\"Acurácia\",\n",
    "        titulo=\"Boxplot - Leave-One-Out (Agrupado por Blocos)\"\n",
    "    )\n",
    "\n",
    "    # Gera gráfico de barras com acurácias médias\n",
    "    df_plot = pd.DataFrame({\n",
    "        \"Modelo\": list(resultados.keys()),\n",
    "        \"Acurácia\": [np.mean(v) for v in resultados.values()]\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=\"Modelo\", y=\"Acurácia\", data=df_plot)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.title(\"Acurácia dos Modelos - Leave-One-Out\")\n",
    "    plt.ylabel(\"Acurácia\")\n",
    "    plt.xlabel(\"Modelos\")\n",
    "    plt.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.6)\n",
    "    plt.xticks(rotation=15)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / \"barplot.png\", dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Barplot salvo em:\", output_dir / \"barplot.png\")\n",
    "\n",
    "    # Prepara os dados para treino final\n",
    "    X = df.drop(columns=[\"gender\"]).values\n",
    "    y = df[\"gender\"].values\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Treina o melhor modelo com todos os dados\n",
    "    modelo_final = clone(algorithms[melhor_modelo_nome])\n",
    "    modelo_final.fit(X_scaled, y)\n",
    "\n",
    "    # Salva informações do melhor modelo\n",
    "    with open(output_dir / \"melhor_modelo.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Melhor modelo: {melhor_modelo_nome}\\nAcurácia: {melhor_acc:.4f}\")\n",
    "\n",
    "    # Salva o scaler + modelo treinado juntos\n",
    "    joblib.dump((scaler, modelo_final), output_dir / \"melhor_modelo.pkl\")\n",
    "\n",
    "    print(\"\\nAnálise concluída com sucesso!\")\n",
    "    print(f\"\\nMelhor modelo: {melhor_modelo_nome} (Acurácia: {melhor_acc:.4f})\")\n",
    "    print(\"Modelo final salvo em:\", output_dir / \"melhor_modelo.pkl\")\n",
    "\n",
    "# Executa a análise se o script for chamado diretamente\n",
    "if __name__ == \"__main__\":\n",
    "    run_analysis(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0ca3e5",
   "metadata": {},
   "source": [
    "## -------------------- 11. Validação Cruzada com Grid Search --------------------\n",
    "\n",
    "Esta etapa avalia o desempenho de múltiplos classificadores utilizando validação cruzada estratificada de 3 folds (3-fold Stratified Cross-Validation), com busca de hiperparâmetros (`GridSearchCV`) para alguns modelos.\n",
    "\n",
    "**Modelos utilizados:**\n",
    "- Decision Tree (com e sem limite de profundidade)\n",
    "- k-Nearest Neighbors (k = 3, 5, 7)\n",
    "- Naive Bayes\n",
    "- Support Vector Machine (Linear e RBF com `SGDClassifier`)\n",
    "\n",
    "**Técnicas aplicadas:**\n",
    "1. **Normalização:** os dados são padronizados (`StandardScaler`).\n",
    "2. **Nested Cross-Validation:** para cada modelo, aplica-se `GridSearchCV` internamente (se aplicável) e `cross_val_score` externamente.\n",
    "3. **Avaliação Final:** após validação externa, o melhor modelo é treinado em todo o conjunto.\n",
    "4. **Relatórios:** são geradas as matrizes de confusão, relatório de classificação, boxplots e gráficos de barras comparando acurácias médias.\n",
    "\n",
    "O melhor modelo é salvo com o `scaler` em `results/cross-validation/melhor_modelo.pkl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27be1704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lê o banco de dados de treino/teste\n",
    "df = pd.read_csv(arquivo_treino_validacao)\n",
    "\n",
    "# Separa atributos (X) e rótulos (y)\n",
    "X = df.drop(columns=[\"gender\"])\n",
    "y = df[\"gender\"]\n",
    "\n",
    "# 2. Cria e limpa diretório de resultados\n",
    "output_dir = Path(\"results/cross-validation\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Remove arquivos e subpastas antigas\n",
    "for item in output_dir.iterdir():\n",
    "    if item.is_file():\n",
    "        item.unlink()\n",
    "    elif item.is_dir():\n",
    "        shutil.rmtree(item)\n",
    "\n",
    "# 3. Padroniza os dados com média 0 e desvio padrão 1\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 4. Define os modelos e seus hiperparâmetros (grid search)\n",
    "modelos_com_grid = {\n",
    "    \"Decision Tree\": (DecisionTreeClassifier(random_state=42), {\n",
    "        'max_depth': [3, 5, 7, None],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }),\n",
    "    \"Big Tree\": (DecisionTreeClassifier(random_state=42), {}),\n",
    "    \"kNN\": (KNeighborsClassifier(), {\n",
    "        'n_neighbors': [3, 5, 7]\n",
    "    }),\n",
    "    \"Naive Bayes\": (GaussianNB(), {}),\n",
    "    \"SVM Linear\": (LinearSVC(random_state=42, dual=False, max_iter=10000), {\n",
    "        'C': [0.1, 1, 10]\n",
    "    }),\n",
    "    \"SVM RBF (Fast)\": (SGDClassifier(loss='hinge', penalty='l2', max_iter=1000, random_state=42), {\n",
    "        'alpha': [0.0001, 0.001, 0.01]\n",
    "    })\n",
    "}\n",
    "\n",
    "# 5. Define validações interna e externa (nested CV)\n",
    "inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "outer_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# 6. Inicializa estruturas para armazenar resultados\n",
    "resultados_val = {}\n",
    "melhor_modelo = None\n",
    "melhor_nome = \"\"\n",
    "melhor_acc = 0\n",
    "relatorio_path = output_dir / \"relatorio.txt\"\n",
    "\n",
    "# 7. Avalia os modelos\n",
    "with open(relatorio_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Relatório Cross-Validation (modelo treinado em todos os dados após validação externa):\\n\\n\")\n",
    "\n",
    "    # Itera sobre os modelos e grids\n",
    "    for nome, (modelo, grid) in modelos_com_grid.items():\n",
    "        print(f\"\\nModelo: {nome}\")\n",
    "\n",
    "        # Se houver grid, usa GridSearchCV com validação interna\n",
    "        if grid:\n",
    "            grid_search = GridSearchCV(modelo, grid, cv=inner_cv, scoring='accuracy', n_jobs=-1)\n",
    "        else:\n",
    "            grid_search = modelo\n",
    "\n",
    "        # Realiza validação cruzada externa\n",
    "        scores = cross_val_score(grid_search, X=X_scaled, y=y, cv=outer_cv, n_jobs=-1)\n",
    "        resultados_val[nome] = scores\n",
    "\n",
    "        # Treina modelo final com todos os dados para gerar relatório\n",
    "        if hasattr(grid_search, 'fit'):\n",
    "            grid_search.fit(X_scaled, y)\n",
    "            final_model = grid_search.best_estimator_ if hasattr(grid_search, 'best_estimator_') else grid_search\n",
    "        else:\n",
    "            final_model = modelo.fit(X_scaled, y)\n",
    "\n",
    "        # Prediz rótulos e calcula acurácia\n",
    "        y_pred = final_model.predict(X_scaled)\n",
    "        acc = accuracy_score(y, y_pred)\n",
    "\n",
    "        # Gera e escreve relatório de classificação\n",
    "        relatorio = classification_report(y, y_pred, target_names=[\"Women\", \"Men\"], digits=4)\n",
    "        f.write(f\"Modelo: {nome}\\n\")\n",
    "        f.write(relatorio)\n",
    "        f.write(\"\\n\" + \"-\" * 60 + \"\\n\")\n",
    "        print(relatorio)\n",
    "\n",
    "        # Gera e salva matriz de confusão\n",
    "        cm = confusion_matrix(y, y_pred, labels=[0, 1])\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=[\"Women\", \"Men\"], yticklabels=[\"Women\", \"Men\"])\n",
    "        plt.xlabel(\"Classe Predita\")\n",
    "        plt.ylabel(\"Classe Real\")\n",
    "        plt.title(f\"Matriz de Confusão - {nome}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_dir / f\"{nome}_matriz_confusao.png\", dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # Atualiza melhor modelo, se necessário\n",
    "        if acc > melhor_acc:\n",
    "            melhor_acc = acc\n",
    "            melhor_modelo = final_model\n",
    "            melhor_nome = nome\n",
    "\n",
    "# 8. Gera boxplot com acurácias da validação cruzada\n",
    "def plot_boxplot(result, boxplot_file, y_label_text=\"Score\", titulo=\"Boxplot\"):\n",
    "    plt.style.use('default')\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    cleaned = [pd.Series(v).dropna() for v in result.values()]\n",
    "    plt.boxplot(cleaned, tick_labels=list(result.keys()))\n",
    "    plt.title(titulo)\n",
    "    plt.ylabel(y_label_text)\n",
    "    plt.xticks(rotation=15)\n",
    "    plt.grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(boxplot_file, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Boxplot salvo em: {boxplot_file}\")\n",
    "\n",
    "plot_boxplot(\n",
    "    result=resultados_val,\n",
    "    boxplot_file=output_dir / \"boxplot.png\",\n",
    "    y_label_text=\"Acurácia\",\n",
    "    titulo=\"Boxplot - Cross-Validation\"\n",
    ")\n",
    "\n",
    "# 9. Gera gráfico de barras com média e desvio padrão\n",
    "df_stats = pd.DataFrame({\n",
    "    \"Modelo\": list(resultados_val.keys()),\n",
    "    \"Acurácia Média\": [np.mean(v) for v in resultados_val.values()],\n",
    "    \"Desvio Padrão\": [np.std(v) for v in resultados_val.values()]\n",
    "})\n",
    "\n",
    "# Cria o gráfico de barras\n",
    "plt.figure(figsize=(12, 7))\n",
    "sns.barplot(x=\"Modelo\", y=\"Acurácia Média\", data=df_stats)\n",
    "plt.grid(True, axis='y', linestyle='--', alpha=0.6)\n",
    "plt.title(\"Acurácia Média por Modelo\", pad=15, fontweight='bold')\n",
    "plt.ylim(0, 1.05)\n",
    "plt.xticks(rotation=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / \"barplot.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 10. Salva o melhor modelo e o scaler em disco\n",
    "joblib.dump((scaler, melhor_modelo), output_dir / \"melhor_modelo.pkl\")\n",
    "\n",
    "# Salva nome e acurácia do melhor modelo\n",
    "with open(output_dir / \"melhor_modelo.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"Melhor modelo: {melhor_nome}\\nAcurácia: {melhor_acc:.4f}\")\n",
    "\n",
    "# Mensagens finais\n",
    "print(\"\\nAnálise concluída com sucesso!\")\n",
    "print(f\"Melhor modelo: {melhor_nome} (Acurácia: {melhor_acc:.4f})\")\n",
    "print(\"Resultados salvos em:\", output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3495be7",
   "metadata": {},
   "source": [
    "## -------------------- 12. Comparação Visual dos Classificadores em Dados Sintéticos --------------------\n",
    "\n",
    "Esta etapa tem como objetivo **visualizar o comportamento dos classificadores** utilizados no projeto\n",
    "em **dados sintéticos bidimensionais**.\n",
    "\n",
    "São usados três conjuntos de dados artificiais:\n",
    "- Moons (semiluas com ruído)\n",
    "- Circles (círculos concêntricos)\n",
    "- Dados gaussianos simulados com 2 atributos informativos\n",
    "\n",
    "Seis classificadores são treinados em cada conjunto e as **fronteiras de decisão** são desenhadas, \n",
    "permitindo comparar:\n",
    "- Como cada modelo separa regiões de decisão\n",
    "- Robustez frente a diferentes distribuições\n",
    "- Comportamento visual (overfitting vs generalização)\n",
    "\n",
    "O resultado é um gráfico com 3 linhas (uma para cada dataset) e 7 colunas (dados de entrada + 6 classificadores).\n",
    "\n",
    "Este gráfico não utiliza os dados reais do projeto (dados CSI). Ele tem caráter ilustrativo, gerando dados sintéticos bidimensionais para demonstrar visualmente como os classificadores se comportam em diferentes cenários. Serve como apoio didático e não interfere diretamente nos resultados do experimento com os dados reais.\n",
    "\n",
    "O arquivo gerado é salvo como `results/classifier_comparison.png`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3572a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista com nomes dos classificadores utilizados\n",
    "names = [\n",
    "    \"kNN\", \"Decision Tree\", \"Big Tree\", \"Naive Bayes\", \"SVM Linear\", \"SVM RBF\"\n",
    "]\n",
    "\n",
    "# Lista com instâncias dos classificadores configurados\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),                      # kNN com k=3\n",
    "    DecisionTreeClassifier(max_depth=5),          # Árvore com profundidade limitada\n",
    "    DecisionTreeClassifier(),                     # Árvore sem limitação de profundidade\n",
    "    GaussianNB(),                                 # Classificador Naive Bayes\n",
    "    SVC(kernel=\"linear\", C=0.025, probability=True),  # SVM com kernel linear\n",
    "    SVC(gamma=2, C=1, probability=True),              # SVM com kernel RBF\n",
    "]\n",
    "\n",
    "# Conjuntos de dados sintéticos para visualização das fronteiras de decisão\n",
    "datasets = [\n",
    "    make_moons(noise=0.3, random_state=0),        # Dados em formato de semiluas\n",
    "    make_circles(noise=0.2, factor=0.5, random_state=1),  # Dados em círculos concêntricos\n",
    "    make_classification(                          # Dados gaussianos com 2 atributos informativos\n",
    "        n_features=2, n_redundant=0, n_informative=2,\n",
    "        random_state=42, n_clusters_per_class=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Ignora avisos de convergência, especialmente úteis para modelos como MLP (não usados aqui, mas por segurança)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "    # Cria figura com layout grande para todas as subplots\n",
    "    figure = plt.figure(figsize=(20, 6))\n",
    "\n",
    "    # Índice da subplot\n",
    "    i = 1\n",
    "\n",
    "    # Itera sobre os datasets sintéticos\n",
    "    for ds in datasets:\n",
    "        # Separa atributos e rótulos\n",
    "        X, y = ds\n",
    "\n",
    "        # Normaliza os atributos\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "\n",
    "        # Separa dados de treino e teste (60/40)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "        # Primeira coluna: dados de entrada\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        ax.set_title(\"Input data\")\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm, edgecolors='k')\n",
    "        i += 1\n",
    "\n",
    "        # Colunas seguintes: classificadores aplicados\n",
    "        for name, clf in zip(names, classifiers):\n",
    "            ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "\n",
    "            # Treina o classificador\n",
    "            clf.fit(X_train, y_train)\n",
    "\n",
    "            # Avalia acurácia no conjunto de teste\n",
    "            score = clf.score(X_test, y_test)\n",
    "\n",
    "            # Gera a visualização da fronteira de decisão\n",
    "            display = DecisionBoundaryDisplay.from_estimator(\n",
    "                clf, X, response_method=\"predict\", cmap=plt.cm.coolwarm, alpha=0.8, ax=ax\n",
    "            )\n",
    "\n",
    "            # Sobrepõe os pontos de teste\n",
    "            ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=plt.cm.coolwarm, edgecolors='k')\n",
    "\n",
    "            # Título do gráfico com nome e acurácia\n",
    "            ax.set_title(f\"{name}\\nAccuracy: {score:.2f}\")\n",
    "            i += 1\n",
    "\n",
    "    # Ajusta o layout geral da figura\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Salva o gráfico final em alta resolução\n",
    "    plt.savefig(\"results/classifier_comparison.png\", dpi=300)\n",
    "\n",
    "    # Fecha a figura\n",
    "    plt.close()\n",
    "\n",
    "    # Mensagem informando o local do arquivo salvo\n",
    "    print(\"Gráfico de Comparação Salvo em: results/classifier_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304cbcaf",
   "metadata": {},
   "source": [
    "## -------------------- 13. Análise com Árvore / Visualização de Modelos --------------------\n",
    "\n",
    "Este bloco exporta e visualiza os modelos finais que foram salvos durante as etapas de validação (Hold-Out, Cross-Validation e Leave-One-Out), mas **somente se o modelo salvo for uma `DecisionTreeClassifier`**.\n",
    "\n",
    "**O que ele faz:**\n",
    "\n",
    "1. Lê novamente os dados originais e prepara `X` e `y` com `convert_gender_to_numeric`.\n",
    "2. Verifica os caminhos dos modelos salvos em:\n",
    "   - `results/hold-out/melhor_modelo.pkl`\n",
    "   - `results/cross-validation/melhor_modelo.pkl`\n",
    "   - `results/leave-one-out/melhor_modelo.pkl`\n",
    "3. Para cada modelo:\n",
    "   - Carrega o arquivo `.pkl`.\n",
    "   - Verifica se é uma árvore de decisão.\n",
    "   - Se for, gera um `.dot` com `export_graphviz` e exporta o gráfico `.png` com `graphviz`.\n",
    "\n",
    "Os arquivos `.png` gerados são salvos em `results/arvores/arvore_<tecnica>_<modelo>.png`.\n",
    "\n",
    "Isso permite inspecionar visualmente a lógica usada pelos classificadores baseados em árvore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4447b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o dataset de treino/validação a partir do arquivo CSV\n",
    "df = pd.read_csv(arquivo_treino_validacao)\n",
    "\n",
    "# Converte a coluna 'gender' para valores numéricos (f → 0, m → 1)\n",
    "df_full = convert_gender_to_numeric(df.copy())\n",
    "\n",
    "# Define o diretório onde as árvores serão salvas\n",
    "output_dir = Path(\"results/arvores\")\n",
    "\n",
    "# Cria o diretório se ele ainda não existir\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Remove arquivos e subpastas antigas do diretório\n",
    "for item in output_dir.iterdir():\n",
    "    if item.is_file():\n",
    "        item.unlink()  # Remove arquivo individual\n",
    "    elif item.is_dir():\n",
    "        shutil.rmtree(item)  # Remove subdiretório inteiro\n",
    "\n",
    "# Separa os atributos (X) e a variável alvo (y)\n",
    "X = df_full.drop(\"gender\", axis=1)\n",
    "y = df_full[\"gender\"]\n",
    "\n",
    "# Define os caminhos dos melhores modelos salvos de cada técnica\n",
    "avaliacoes = {\n",
    "    \"hold-out\": Path(\"results/hold-out/melhor_modelo.pkl\"),\n",
    "    \"cross-validation\": Path(\"results/cross-validation/melhor_modelo.pkl\"),\n",
    "    \"leave-one-out\": Path(\"results/leave-one-out/melhor_modelo.pkl\")\n",
    "}\n",
    "\n",
    "# Percorre cada técnica e seu respectivo caminho de modelo salvo\n",
    "for tecnica, caminho_modelo in avaliacoes.items():\n",
    "    \n",
    "    # Verifica se o arquivo do modelo existe\n",
    "    if not caminho_modelo.exists():\n",
    "        print(f\"Modelo não encontrado: {caminho_modelo}\")\n",
    "        continue\n",
    "\n",
    "    # Carrega o modelo salvo com joblib\n",
    "    print(f\"Carregando modelo salvo de: {caminho_modelo}\")\n",
    "    modelo_geral = joblib.load(caminho_modelo)\n",
    "\n",
    "    # Se o modelo foi salvo como tupla (scaler, modelo), extrai só o modelo\n",
    "    if isinstance(modelo_geral, tuple):\n",
    "        _, modelo_geral = modelo_geral\n",
    "\n",
    "    # Ignora se o modelo não for uma árvore de decisão\n",
    "    if not isinstance(modelo_geral, DecisionTreeClassifier):\n",
    "        print(f\"Ignorado: {tecnica} não é DecisionTreeClassifier.\\n\")\n",
    "        continue\n",
    "\n",
    "    # Obtém o nome da classe do modelo (ex: DecisionTreeClassifier)\n",
    "    nome_modelo = modelo_geral.__class__.__name__\n",
    "\n",
    "    # Constrói um nome seguro para o arquivo, substituindo caracteres especiais\n",
    "    nome_seguro = re.sub(r\"[^\\w\\-]\", \"_\", nome_modelo)\n",
    "\n",
    "    # Define caminho do arquivo .dot (estrutura da árvore)\n",
    "    dot_path = Path(f\"results/arvores/arvore_{tecnica}_{nome_seguro}.dot\")\n",
    "\n",
    "    # Define caminho da imagem .png gerada a partir da árvore\n",
    "    png_path = Path(f\"results/arvores/arvore_{tecnica}_{nome_seguro}.png\")\n",
    "\n",
    "    # Exporta a árvore de decisão para o formato .dot\n",
    "    export_graphviz(\n",
    "        modelo_geral,\n",
    "        out_file=str(dot_path),\n",
    "        feature_names=X.columns,\n",
    "        class_names=[\"Women\", \"Men\"],\n",
    "        rounded=True,\n",
    "        filled=True\n",
    "    )\n",
    "\n",
    "    # Lê o arquivo .dot e renderiza como imagem .png\n",
    "    graph = Source.from_file(str(dot_path))\n",
    "    graph.render(str(png_path.with_suffix(\"\")), format=\"png\", cleanup=True)\n",
    "\n",
    "    # Informa no terminal que a árvore foi salva\n",
    "    print(f\"Árvore salva como: {png_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a0814e",
   "metadata": {},
   "source": [
    "## -------------------- 14. Geração das Curvas ROC --------------------\n",
    "\n",
    "Esta etapa visualiza a **performance dos classificadores** na distinção entre as classes “Men” e “Women” com base nas curvas ROC (Receiver Operating Characteristic), que comparam a taxa de verdadeiros positivos (TPR) com a de falsos positivos (FPR). Também é exibida a AUC (Área sob a Curva), métrica que representa a capacidade de separação do modelo.\n",
    "\n",
    "**Etapas executadas:**\n",
    "\n",
    "1. **Leitura e preparação do conjunto real de teste.**\n",
    "2. **Padronização dos dados com `StandardScaler`.**\n",
    "3. **Geração das curvas ROC para 3 técnicas:**\n",
    "   - **Hold-Out:** treino/validação com split 80/20\n",
    "   - **Cross-Validation (3-fold):** agregação das predições ao longo das dobras\n",
    "   - **Leave-One-Out:** uma predição por rodada\n",
    "4. **Para cada técnica e classificador:**\n",
    "   - Aplica o modelo sobre os dados padronizados\n",
    "   - Usa `predict_proba` ou `decision_function` para obter scores\n",
    "   - Salva um gráfico `PNG` por técnica em `results/curvas_roc/roc_<tecnica>.png`\n",
    "\n",
    "Isso permite comparar visualmente o desempenho dos modelos, inclusive com diferentes limiares de decisão.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3937edb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lê o dataset real de teste com rótulo \"gender\"\n",
    "df = pd.read_csv(arquivo_teste_real)\n",
    "\n",
    "# Cria diretório onde os gráficos de curva ROC serão salvos\n",
    "roc_dir = Path(\"results/curvas_roc\")\n",
    "roc_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Limpa todos os arquivos e pastas dentro do diretório de resultados\n",
    "for item in roc_dir.iterdir():\n",
    "    if item.is_file():\n",
    "        item.unlink()\n",
    "    elif item.is_dir():\n",
    "        shutil.rmtree(item)\n",
    "\n",
    "# Função que gera e salva curvas ROC para um conjunto de classificadores\n",
    "def plot_save_roc_curves(y_true_dict, y_score_dict, technique_name):\n",
    "    plt.figure(figsize=(10,7))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    cores = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "\n",
    "    for idx, model_name in enumerate(y_true_dict.keys()):\n",
    "        y_true = y_true_dict[model_name]\n",
    "        y_score = y_score_dict[model_name]\n",
    "\n",
    "        y_true = np.array(y_true)\n",
    "        y_score = np.array(y_score)\n",
    "\n",
    "        # Garante que existem pelo menos duas classes\n",
    "        if len(np.unique(y_true)) < 2 or len(np.unique(y_score)) < 2:\n",
    "            continue\n",
    "\n",
    "        # Gera pontos da curva ROC e calcula AUC\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        # Plota a curva ROC com rótulo do modelo e AUC\n",
    "        plt.plot(fpr, tpr, label=f\"{model_name} (AUC={roc_auc:.3f})\", lw=2, color=cores[idx % len(cores)])\n",
    "\n",
    "    # Linha de referência aleatória\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Aleatório (AUC = 0.5)')\n",
    "\n",
    "    # Define eixos e título\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"Falso Positivo (FPR)\", fontsize=12)\n",
    "    plt.ylabel(\"Verdadeiro Positivo (TPR)\", fontsize=12)\n",
    "    plt.title(f\"Curva ROC - {technique_name}\", fontsize=14, fontweight='bold')\n",
    "    plt.legend(loc=\"lower right\", fontsize=10)\n",
    "    plt.grid(True, alpha=0.4)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Salva gráfico\n",
    "    fname = roc_dir / f\"roc_{technique_name.replace(' ', '_').lower()}.png\"\n",
    "    plt.savefig(fname, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Curva roc de {technique_name} salva em {fname}\")\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# Etapa comum: separa atributos e rótulo, normaliza os dados\n",
    "X = df.drop(columns=[\"gender\"]).values\n",
    "y = df[\"gender\"].values\n",
    "scaler = StandardScaler()\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "# GERAÇÃO DA CURVA ROC PARA HOLD-OUT\n",
    "print(\"Gerando curva roc de Hold-Out\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "y_true_dict_ho = {}\n",
    "y_score_dict_ho = {}\n",
    "\n",
    "# Para cada modelo, treina e gera scores de probabilidade ou decisão\n",
    "for name, modelo in algorithms.items():\n",
    "    clf = clone(modelo)\n",
    "    clf.fit(X_train, y_train)\n",
    "    if hasattr(clf, \"predict_proba\"):\n",
    "        y_score = clf.predict_proba(X_test)[:, 1]\n",
    "    elif hasattr(clf, \"decision_function\"):\n",
    "        y_score = clf.decision_function(X_test)\n",
    "    else:\n",
    "        y_score = clf.predict(X_test)\n",
    "    y_true_dict_ho[name] = y_test\n",
    "    y_score_dict_ho[name] = y_score\n",
    "\n",
    "# Gera a curva ROC do Hold-Out\n",
    "plot_save_roc_curves(y_true_dict_ho, y_score_dict_ho, \"Hold-Out\")\n",
    "\n",
    "# GERAÇÃO DA CURVA ROC PARA CROSS-VALIDATION\n",
    "print(\"Gerando curva roc de Cross-Validation\")\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y_true_dict_cv = {}\n",
    "y_score_dict_cv = {}\n",
    "\n",
    "for name, modelo in algorithms.items():\n",
    "    y_true_cv = []\n",
    "    y_score_cv = []\n",
    "    for train_idx, test_idx in skf.split(X_scaled, y):\n",
    "        clf = clone(modelo)\n",
    "        clf.fit(X_scaled[train_idx], y[train_idx])\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            y_score = clf.predict_proba(X_scaled[test_idx])[:, 1]\n",
    "        elif hasattr(clf, \"decision_function\"):\n",
    "            y_score = clf.decision_function(X_scaled[test_idx])\n",
    "        else:\n",
    "            y_score = clf.predict(X_scaled[test_idx])\n",
    "        y_true_cv.extend(y[test_idx])\n",
    "        y_score_cv.extend(y_score)\n",
    "    y_true_dict_cv[name] = np.array(y_true_cv)\n",
    "    y_score_dict_cv[name] = np.array(y_score_cv)\n",
    "\n",
    "# Gera a curva ROC do Cross-Validation\n",
    "plot_save_roc_curves(y_true_dict_cv, y_score_dict_cv, \"Cross-Validation\")\n",
    "\n",
    "# GERAÇÃO DA CURVA ROC PARA LEAVE-ONE-OUT\n",
    "print(\"Gerando curva roc de Leave-One-Out\")\n",
    "loo = LeaveOneOut()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y_true_dict_loo = {}\n",
    "y_score_dict_loo = {}\n",
    "\n",
    "for name, modelo in algorithms.items():\n",
    "    y_true_loo = []\n",
    "    y_score_loo = []\n",
    "    for train_idx, test_idx in loo.split(X_scaled):\n",
    "        clf = clone(modelo)\n",
    "        clf.fit(X_scaled[train_idx], y[train_idx])\n",
    "        if hasattr(clf, \"predict_proba\"):\n",
    "            y_score = clf.predict_proba(X_scaled[test_idx])[:, 1]\n",
    "        elif hasattr(clf, \"decision_function\"):\n",
    "            y_score = clf.decision_function(X_scaled[test_idx])\n",
    "        else:\n",
    "            y_score = clf.predict(X_scaled[test_idx])\n",
    "        y_true_loo.append(y[test_idx][0])\n",
    "        y_score_loo.append(y_score[0])\n",
    "    y_true_dict_loo[name] = np.array(y_true_loo)\n",
    "    y_score_dict_loo[name] = np.array(y_score_loo)\n",
    "\n",
    "# Gera a curva ROC do Leave-One-Out\n",
    "plot_save_roc_curves(y_true_dict_loo, y_score_dict_loo, \"Leave-One-Out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc2935b",
   "metadata": {},
   "source": [
    "## -------------------- 15. Avaliação Final - Teste Real --------------------\n",
    "\n",
    "Nesta etapa, os modelos finalistas de cada técnica (Hold-Out, Cross-Validation e Leave-One-Out) são aplicados ao conjunto real de teste (`db_800.csv`) para avaliar sua capacidade de generalização.\n",
    "\n",
    "Além do relatório de classificação salvo em `.txt`, é gerada uma imagem da matriz de confusão para cada modelo avaliado, permitindo análise visual da performance.\n",
    "\n",
    "**O que o código realiza:**\n",
    "- Suprime `warnings` de conversão e usuários para facilitar a leitura dos logs\n",
    "- Lê os dados reais de teste\n",
    "- Aplica o modelo salvo para cada técnica, com ou sem `StandardScaler`\n",
    "- Detecta o nome do classificador, tratando `DecisionTreeClassifier(max_depth=None)` como \"Big Tree\"\n",
    "- Gera:\n",
    "  - Relatórios de classificação salvos em `results/teste_real/`\n",
    "  - Matrizes de confusão salvas como imagens `PNG` no mesmo diretório\n",
    "  - Impressão dos relatórios no terminal com título da técnica e modelo\n",
    "\n",
    "Esse processo finaliza a comparação objetiva dos modelos com dados nunca vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99971546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suprime warnings indesejados durante execução dos classificadores\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "\n",
    "# Lê o conjunto real de teste\n",
    "df_teste = pd.read_csv(arquivo_teste_real)\n",
    "\n",
    "# Separa os atributos (X_test) e os rótulos (y_test)\n",
    "X_test = df_teste.drop(\"gender\", axis=1)  # Remove coluna de classe\n",
    "y_test = df_teste[\"gender\"]  # Define variável alvo\n",
    "\n",
    "# Define os caminhos dos modelos salvos (1 por técnica)\n",
    "tecnicas = {\n",
    "    \"hold-out\": \"results/hold-out/melhor_modelo.pkl\",    \n",
    "    \"leave-one-out\": \"results/leave-one-out/melhor_modelo.pkl\",\n",
    "    \"cross-validation\": \"results/cross-validation/melhor_modelo.pkl\"\n",
    "}\n",
    "\n",
    "# Cria diretório onde os relatórios e gráficos serão salvos\n",
    "dir_saida = Path(\"results/teste_real\")\n",
    "dir_saida.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Executa a avaliação para cada técnica\n",
    "for tecnica, caminho_modelo in tecnicas.items():\n",
    "    try:\n",
    "        # Carrega o modelo (pode ser tupla: (scaler, modelo))\n",
    "        modelo_carregado = joblib.load(caminho_modelo)\n",
    "\n",
    "        # Se for tupla, aplica o scaler ao X_test\n",
    "        if isinstance(modelo_carregado, tuple):\n",
    "            scaler, modelo = modelo_carregado\n",
    "            X_test_scaled = scaler.transform(X_test.values)\n",
    "        else:\n",
    "            modelo = modelo_carregado\n",
    "            X_test_scaled = X_test.values  # Dados crus\n",
    "\n",
    "        # Detecta nome do modelo, tratando árvore sem max_depth como \"Big Tree\"\n",
    "        nome_base = type(modelo).__name__\n",
    "        params = modelo.get_params()\n",
    "        if nome_base == \"DecisionTreeClassifier\" and params.get(\"max_depth\", 1) is None:\n",
    "            nome_modelo_humano = \"Big Tree\"\n",
    "        else:\n",
    "            nome_modelo_humano = nome_base\n",
    "\n",
    "        # Realiza predição sobre o teste real\n",
    "        y_pred = modelo.predict(X_test_scaled)\n",
    "\n",
    "        # Gera métricas de avaliação\n",
    "        acc = accuracy_score(y_test, y_pred)  # Acurácia\n",
    "        relatorio = classification_report(\n",
    "            y_test, y_pred, target_names=[\"Women\", \"Men\"], digits=4, zero_division=0\n",
    "        )\n",
    "        matriz = confusion_matrix(y_test, y_pred, labels=[0, 1])  # Matriz confusão\n",
    "\n",
    "        # Formata título para relatório\n",
    "        titulo = f\"Técnica: {tecnica.replace('-', ' ').title()} | Modelo: {nome_modelo_humano}\"\n",
    "\n",
    "        # Salva o relatório de classificação em .txt\n",
    "        caminho_relatorio = dir_saida / f\"relatorio_{tecnica}_{nome_modelo_humano}.txt\"\n",
    "        with open(caminho_relatorio, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"{titulo}\\n{relatorio}\")\n",
    "        print(f\"\\n\\n{titulo}\\n{relatorio}\")\n",
    "        print(f\"Relatório do melhor modelo de {tecnica} salvo em {caminho_relatorio}\")        \n",
    "\n",
    "        # Gera e salva a imagem da matriz de confusão\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.heatmap(matriz, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=[\"Women\", \"Men\"], yticklabels=[\"Women\", \"Men\"])\n",
    "        plt.xlabel(\"Classe Predita\")\n",
    "        plt.ylabel(\"Classe Real\")\n",
    "        plt.title(f\"{tecnica.replace('-', ' ').title()} - {nome_modelo_humano} - TESTE REAL\")\n",
    "        plt.tight_layout()\n",
    "        caminho_img = dir_saida / f\"matriz_confusao_{tecnica}_{nome_modelo_humano}.png\"\n",
    "        plt.savefig(caminho_img, dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"Matriz de confusão do melhor modelo de {tecnica} salva em {caminho_img}\")\n",
    "\n",
    "    # Caso ocorra erro ao processar alguma técnica (ex: arquivo faltando)\n",
    "    except Exception as e:\n",
    "        print(f\"\\nErro com técnica '{tecnica}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b60accd",
   "metadata": {},
   "source": [
    "## -------------------- Fim do código --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96efe242",
   "metadata": {},
   "outputs": [],
   "source": [
    "fim = time()\n",
    "duracao = strftime('%H:%M:%S', gmtime(fim - inicio))\n",
    "print(f\"\\nTempo execução (HH:mm:ss): {duracao}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
