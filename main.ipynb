{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "936b658a",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################################\n",
    "### Projeto da Disciplina de PO-233                                                                                        #\n",
    "### Título: Identificação de dados biométricos utilizando redes Wireless e aprendizado de máquina                          #\n",
    "### Alunos:                                                                                                                #\n",
    "###         Ágney Lopes Roth Ferraz                                                                                        #\n",
    "###\t        Alexandre Bellargus Silva da Costa                                                                             #\n",
    "###\t        Carlos Renato de Andrade Figueiredo                                                                            #\n",
    "###\t        Gioliano de Oliveira Braga                                                                                     #\n",
    "###\t        Paulo Ricardo Sousa Fonteles de Castro                                                                         #\n",
    "###\t        Wagner Comin Sonaglio                                                                                          #\n",
    "############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae7bc57",
   "metadata": {},
   "source": [
    "## -------------------- 01. Importação de Bibliotecas -------------------- \n",
    "\n",
    "Nesta célula são importadas todas as bibliotecas necessárias para o projeto. As bibliotecas estão organizadas por funcionalidade:\n",
    "\n",
    "Nesta célula, são importadas todas as bibliotecas necessárias para o projeto. As bibliotecas estão organizadas por funcionalidade:\n",
    "\n",
    "- **Manipulação de dados**: `numpy` e `pandas` para operações numéricas e tabelas (DataFrames).\n",
    "- **Visualização de dados**: `matplotlib`, `seaborn` e `DecisionBoundaryDisplay` para criação de gráficos, dispersões, fronteiras de decisão e análise visual.\n",
    "- **Machine Learning**: classificadores (`DecisionTree`, `kNN`, `SVM`, `NaiveBayes`, `RandomForest`, `MLP`, `QDA`), métricas (`accuracy`, `precision`, `recall`, `f1`, `confusion_matrix`, `ROC`, `AUC`) e redução de dimensionalidade com `PCA`.\n",
    "- **Validação e treinamento**: `train_test_split`, `cross_val_score`, `clone`, usados para dividir os dados e validar os modelos.\n",
    "- **Visualização de árvores de decisão**: `graphviz` para exportar e renderizar visualmente o modelo de árvore.\n",
    "- **Utilitários do sistema**: `os`, `pathlib`, `timeit`, `warnings` para controle de diretórios, tempo de execução, caminhos multiplataforma e tratamento de avisos.\n",
    "\n",
    "Essas importações preparam o ambiente para todas as etapas do aprendizado de máquina: pré-processamento, treino, avaliação e visualização.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cc41994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================\n",
    "# Bibliotecas essenciais\n",
    "# ===============================================================\n",
    "import os                      # Manipulação de arquivos\n",
    "from pathlib import Path       # Caminhos multiplataforma\n",
    "import numpy as np             # Operações numéricas\n",
    "import pandas as pd            # Manipulação de DataFrames\n",
    "import warnings                # Controle de avisos\n",
    "\n",
    "# ===============================================================\n",
    "# Visualização de dados\n",
    "# ===============================================================\n",
    "import seaborn as sns          # Gráficos estatísticos\n",
    "import matplotlib.pyplot as plt  # Gráficos gerais\n",
    "from graphviz import Source    # Renderização de árvores .dot\n",
    "from sklearn.inspection import DecisionBoundaryDisplay  # Fronteiras\n",
    "\n",
    "# ===============================================================\n",
    "# Medição de tempo\n",
    "# ===============================================================\n",
    "from timeit import default_timer as timer  # Cronômetro\n",
    "\n",
    "# ===============================================================\n",
    "# Aprendizado de Máquina\n",
    "# ---------------------------------------------------------------\n",
    "# Classificadores\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Pré-processamento e validação\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "\n",
    "\n",
    "# Avaliação de desempenho\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report,\n",
    "    roc_curve, auc\n",
    ")\n",
    "\n",
    "# Redução de dimensionalidade\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Geração de dados sintéticos\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "\n",
    "# ===============================================================\n",
    "# Configurações do Projeto\n",
    "# ===============================================================\n",
    "from sklearn.exceptions import ConvergenceWarning  # Suprimir avisos do MLP\n",
    "from config import results_dir, algorithms, cv      # Parâmetros externos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2a5e8b",
   "metadata": {},
   "source": [
    "## -------------------- 02. Lista de Databases disponíveis -------------------- \n",
    "\n",
    "Lista os arquivos de dados .csv disponíveis para o treino/validação/teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20d142c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos csv disponíveis na pasta /db/:\n",
      "- db_3200.csv\n",
      "- db_400.csv\n",
      "- db_4000.csv\n",
      "- db_800.csv\n"
     ]
    }
   ],
   "source": [
    "# Lista de arquivos .db no diretório atual\n",
    "\n",
    "db_path = Path('./db')  # Caminho para a pasta db\n",
    "arquivos_db = list(db_path.glob('*.csv'))  # Procura arquivos .db dentro de /db/\n",
    "\n",
    "print(\"Arquivos csv disponíveis na pasta /db/:\")\n",
    "for arquivo in arquivos_db:\n",
    "    print(\"-\", arquivo.name)  # Usa .name para mostrar só o nome do arquivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ebe4a9",
   "metadata": {},
   "source": [
    "## -------------------- 03. Escolha e Carregamento do Dataset -------------------- \n",
    "\n",
    "Esta etapa realiza o carregamento do conjunto de dados a partir de um arquivo `.csv`. Essa é a primeira etapa prática do pipeline de machine learning, preparando os dados para o pré-processamento e análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0673d5f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>rpi1_sc-118</th>\n",
       "      <th>rpi1_sc-111</th>\n",
       "      <th>rpi1_sc2</th>\n",
       "      <th>rpi1_sc32</th>\n",
       "      <th>rpi1_sc67</th>\n",
       "      <th>rpi1_sc106</th>\n",
       "      <th>rpi1_sc120</th>\n",
       "      <th>rpi1_sc121</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>521.4720</td>\n",
       "      <td>492.8976</td>\n",
       "      <td>128</td>\n",
       "      <td>38.2884</td>\n",
       "      <td>55.9464</td>\n",
       "      <td>1085.1179</td>\n",
       "      <td>693.6801</td>\n",
       "      <td>669.0209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>397.3109</td>\n",
       "      <td>170.5579</td>\n",
       "      <td>128</td>\n",
       "      <td>143.9514</td>\n",
       "      <td>42.2019</td>\n",
       "      <td>422.0569</td>\n",
       "      <td>216.6010</td>\n",
       "      <td>343.0015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>480.0104</td>\n",
       "      <td>532.8884</td>\n",
       "      <td>128</td>\n",
       "      <td>35.8469</td>\n",
       "      <td>56.3027</td>\n",
       "      <td>1142.7905</td>\n",
       "      <td>626.5693</td>\n",
       "      <td>593.6548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>533.4566</td>\n",
       "      <td>488.0349</td>\n",
       "      <td>128</td>\n",
       "      <td>42.0476</td>\n",
       "      <td>50.3289</td>\n",
       "      <td>1060.5376</td>\n",
       "      <td>688.3204</td>\n",
       "      <td>650.2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>532.5233</td>\n",
       "      <td>500.6815</td>\n",
       "      <td>128</td>\n",
       "      <td>48.6621</td>\n",
       "      <td>54.6260</td>\n",
       "      <td>1070.5597</td>\n",
       "      <td>698.4512</td>\n",
       "      <td>653.9373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  rpi1_sc-118  rpi1_sc-111  rpi1_sc2  rpi1_sc32  rpi1_sc67  \\\n",
       "0       1     521.4720     492.8976       128    38.2884    55.9464   \n",
       "1       1     397.3109     170.5579       128   143.9514    42.2019   \n",
       "2       1     480.0104     532.8884       128    35.8469    56.3027   \n",
       "3       1     533.4566     488.0349       128    42.0476    50.3289   \n",
       "4       1     532.5233     500.6815       128    48.6621    54.6260   \n",
       "\n",
       "   rpi1_sc106  rpi1_sc120  rpi1_sc121  \n",
       "0   1085.1179    693.6801    669.0209  \n",
       "1    422.0569    216.6010    343.0015  \n",
       "2   1142.7905    626.5693    593.6548  \n",
       "3   1060.5376    688.3204    650.2492  \n",
       "4   1070.5597    698.4512    653.9373  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Caso os arquivos sejam alterados, deve-se alterar as seguintes linhas\n",
    "# No item 06: (se necessário - percentual para teste/validação do hold-out)\n",
    "#               X, y, test_size=0.2, stratify=y, random_state=42\n",
    "# No item 13:\n",
    "#               n_experimentos = 10  # total de blocos de experimentos\n",
    "#               tamanho_exp = 320  # tamanho de cada bloco \n",
    "\n",
    "# Diretório base\n",
    "db_dir = Path('db')\n",
    "\n",
    "# Caminhos completos para os arquivos\n",
    "arquivo_treino_validacao = db_dir / 'db_3200.csv'\n",
    "arquivo_teste_real = db_dir / 'db_800.csv'\n",
    "arquivo_pca_271_portadoras = db_dir / 'db_400.csv'\n",
    "\n",
    "# Carregando o banco de treino/validação do hold-out, validação cruzada e leave-one-out\n",
    "df = pd.read_csv(arquivo_treino_validacao)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3ce45a",
   "metadata": {},
   "source": [
    "## -------------------- 04. Conversão de Gênero para Valores Numéricos --------------------\n",
    "\n",
    "Essa função executa o pré-processamento da variável alvo `gender`, convertendo os valores categóricos ('f' e 'm') para valores numéricos (0 e 1), que são aceitos pelos algoritmos de aprendizado de máquina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39ed9a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte coluna 'gender' de 'f'/'m' para 0/1\n",
    "def convert_gender_to_numeric(df):\n",
    "    df['gender'] = df['gender'].replace({'f': 0, 'm': 1})  # troca 'f' por 0 e 'm' por 1\n",
    "    return df  # retorna o DataFrame com a coluna modificada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb02abe9",
   "metadata": {},
   "source": [
    "## -------------------- 05. Visualização da Dispersão entre Portadoras (Pairplot) -------------------- \n",
    "\n",
    "Esta etapa realiza uma análise visual dos dados usando pairplot para verificar a separabilidade entre os gêneros com base nas portadoras. Essa visualização auxilia na etapa de exploração de dados (EDA), ajudando a entender como as variáveis se distribuem e se há padrões visuais úteis para o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c91e031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairplot saved in: results/pair_plot.png\n"
     ]
    }
   ],
   "source": [
    "# Cria o diretório 'results' se ainda não existir\n",
    "Path(\"results\").mkdir(exist_ok=True)\n",
    "\n",
    "# Define as colunas das portadoras\n",
    "portadoras = ['rpi1_sc-118', 'rpi1_sc-111', 'rpi1_sc2', 'rpi1_sc32',\n",
    "              'rpi1_sc67', 'rpi1_sc106', 'rpi1_sc120', 'rpi1_sc121']\n",
    "\n",
    "# Cria uma cópia do DataFrame com apenas as portadoras e o gênero\n",
    "df_plot = df[portadoras + ['gender']].copy()\n",
    "\n",
    "# Converte os valores 0 e 1 para 'Men' e 'Women' (para legenda)\n",
    "df_plot['gender'] = df_plot['gender'].map({0: 'Women', 1: 'Men'})\n",
    "\n",
    "# Cria o gráfico de dispersão múltipla (pairplot)\n",
    "plot = sns.pairplot(df_plot, hue='gender', palette='Set1', corner=True)\n",
    "\n",
    "# Define o título da figura\n",
    "plt.suptitle(\"Carrier Dispersion by Gender\", y=1.02)\n",
    "\n",
    "# Salva o gráfico como imagem\n",
    "plot.savefig(\"results/pair_plot.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Mensagem de confirmação\n",
    "print(\"Pairplot saved in: results/pair_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1f0b9b",
   "metadata": {},
   "source": [
    "## -------------------- 06. Separação do Conjunto de Treino e Validação (80/20) para o Hold-Out --------------------\n",
    "\n",
    "Nesta etapa, o conjunto de dados completo é dividido em dois subconjuntos: 80% para treino e 20% para validação. Essa técnica é conhecida como **validação hold-out**.\n",
    "\n",
    "A variável `X` representa as características (atributos) de entrada e `y` é a variável alvo (`gender`). A função `train_test_split` é usada com estratificação para manter a proporção de classes nos dois conjuntos. Esta divisão é usada posteriormente para avaliar o modelo de forma simples, fora dos esquemas de validação cruzada ou LOEO.\n",
    "\n",
    "> Essa separação só é usada na avaliação final de **validação hold-out**, onde o modelo treinado será testado com 80% dos dados nos 20% restantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c02ffe1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino: (2560, 8), Validação: (640, 8)\n"
     ]
    }
   ],
   "source": [
    "# Separação do conjunto de treino/validação (80/20)\n",
    "\n",
    "X = df.drop('gender', axis=1)\n",
    "y = df['gender']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Treino: {X_train.shape}, Validação: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6fc88e",
   "metadata": {},
   "source": [
    "## -------------------- 07. Treinamento com 80% dos Dados (Hold-Out) --------------------\n",
    "\n",
    "Neste bloco, os principais classificadores do projeto são treinados utilizando 80% do conjunto original de dados (divisão hold-out). O objetivo é preparar cada modelo individualmente para posterior avaliação com os 20% restantes.\n",
    "Os modelos utilizados são:\n",
    "- **kNN** (K-Nearest Neighbors)  \n",
    "- **Decision Tree** (Árvore de decisão limitada)  \n",
    "- **Big Tree** (Árvore sem limite de profundidade)  \n",
    "- **Naive Bayes**  \n",
    "- **SVM Linear**  \n",
    "- **SVM RBF** (com kernel radial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c807f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'kNN' treinado.\n",
      "Modelo 'Decision Tree' treinado.\n",
      "Modelo 'Big Tree' treinado.\n",
      "Modelo 'Naive Bayes' treinado.\n",
      "Modelo 'SVM Linear' treinado.\n",
      "Modelo 'SVM RBF' treinado.\n"
     ]
    }
   ],
   "source": [
    "# Define os classificadores a treinar\n",
    "modelos = {\n",
    "    \"kNN\": KNeighborsClassifier(3),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=5),\n",
    "    \"Big Tree\": DecisionTreeClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"SVM Linear\": SVC(kernel=\"linear\", C=0.025, probability=True),\n",
    "    \"SVM RBF\": SVC(gamma=2, C=1, probability=True)\n",
    "}\n",
    "\n",
    "# Dicionário para armazenar os modelos treinados\n",
    "modelos_treinados = {}\n",
    "\n",
    "# Treinamento de cada modelo com os 80% (X_train, y_train)\n",
    "for nome, modelo in modelos.items():\n",
    "    clf = clone(modelo)\n",
    "    clf.fit(X_train, y_train)\n",
    "    modelos_treinados[nome] = clf\n",
    "    print(f\"Modelo '{nome}' treinado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e521ef2b",
   "metadata": {},
   "source": [
    "## -------------------- 08. Avaliação Hold-Out (com 20% de validação) --------------------\n",
    "\n",
    "Nesta etapa, os modelos treinados com 80% dos dados são avaliados com os 20% restantes, utilizando a estratégia Hold-Out.\n",
    "Para cada classificador (kNN, Decision Tree, Big Tree, Naive Bayes, SVM Linear, SVM RBF), foi gerado um relatório com as métricas de desempenho (precisão, recall, F1-score e suporte).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e74f05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo: kNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Women     0.9816    1.0000    0.9907       320\n",
      "         Men     1.0000    0.9812    0.9905       320\n",
      "\n",
      "    accuracy                         0.9906       640\n",
      "   macro avg     0.9908    0.9906    0.9906       640\n",
      "weighted avg     0.9908    0.9906    0.9906       640\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Modelo: Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Women     0.9846    1.0000    0.9922       320\n",
      "         Men     1.0000    0.9844    0.9921       320\n",
      "\n",
      "    accuracy                         0.9922       640\n",
      "   macro avg     0.9923    0.9922    0.9922       640\n",
      "weighted avg     0.9923    0.9922    0.9922       640\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Modelo: Big Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Women     0.9846    0.9969    0.9907       320\n",
      "         Men     0.9968    0.9844    0.9906       320\n",
      "\n",
      "    accuracy                         0.9906       640\n",
      "   macro avg     0.9907    0.9906    0.9906       640\n",
      "weighted avg     0.9907    0.9906    0.9906       640\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Modelo: Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Women     0.7567    0.7094    0.7323       320\n",
      "         Men     0.7265    0.7719    0.7485       320\n",
      "\n",
      "    accuracy                         0.7406       640\n",
      "   macro avg     0.7416    0.7406    0.7404       640\n",
      "weighted avg     0.7416    0.7406    0.7404       640\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Modelo: SVM Linear\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Women     0.9486    0.9219    0.9350       320\n",
      "         Men     0.9240    0.9500    0.9368       320\n",
      "\n",
      "    accuracy                         0.9359       640\n",
      "   macro avg     0.9363    0.9359    0.9359       640\n",
      "weighted avg     0.9363    0.9359    0.9359       640\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "Modelo: SVM RBF\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Women     0.5000    1.0000    0.6667       320\n",
      "         Men     0.0000    0.0000    0.0000       320\n",
      "\n",
      "    accuracy                         0.5000       640\n",
      "   macro avg     0.2500    0.5000    0.3333       640\n",
      "weighted avg     0.2500    0.5000    0.3333       640\n",
      "\n",
      "------------------------------------------------------------\n",
      "Hold-Out saved in: results/hold-out.txt\n"
     ]
    }
   ],
   "source": [
    "# Garante que o diretório de resultados exista\n",
    "Path(\"results\").mkdir(exist_ok=True)\n",
    "\n",
    "# Caminho do arquivo de saída\n",
    "holdout_file = Path(\"results/hold-out.txt\")\n",
    "\n",
    "# Abre o arquivo para escrita\n",
    "with open(holdout_file, \"w\") as f:\n",
    "    f.write(\"Relatório Hold-Out (20% de validação):\\n\\n\")\n",
    "    \n",
    "    for nome, modelo in modelos_treinados.items():\n",
    "        y_val_pred = modelo.predict(X_val)\n",
    "        relatorio = classification_report(y_val, y_val_pred, target_names=[\"Women\", \"Men\"], zero_division=0, digits=4)\n",
    "        \n",
    "        # Escreve no arquivo\n",
    "        f.write(f\"Modelo: {nome}\\n\")\n",
    "        f.write(relatorio)\n",
    "        f.write(\"\\n\" + \"-\" * 60 + \"\\n\")\n",
    "        \n",
    "        # Exibe no terminal\n",
    "        print(f\"\\nModelo: {nome}\")\n",
    "        print(relatorio)\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "print(\"Hold-Out saved in: results/hold-out.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95740be0",
   "metadata": {},
   "source": [
    "## -------------------- 09. Avaliação com Validação Cruzada para Todos os Algoritmos -------------------- \n",
    "\n",
    "Esta função realiza a avaliação de todos os algoritmos definidos na configuração utilizando validação cruzada estratificada. Essa etapa pertence à fase de avaliação de modelos no pipeline de aprendizado de máquina e permite comparar o desempenho dos classificadores de forma consistente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f407ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roda cross_val_score para todos os algoritmos\n",
    "def generate_cross_val_score_all_alg(df, ycla):\n",
    "    print(\"Starting Assessment.\")  # mensagem de início\n",
    "\n",
    "    result = {}  # dicionário para armazenar os resultados\n",
    "\n",
    "    # percorre todos os algoritmos definidos no dicionário algorithms\n",
    "    for alg, clf in algorithms.items():\n",
    "        print(f\"Processing {alg}...\")  # exibe o nome do algoritmo atual\n",
    "\n",
    "        try:\n",
    "            # executa a validação cruzada e armazena os resultados\n",
    "            result[alg] = cross_val_score(clf, df, ycla, cv=cv)\n",
    "        except Exception as error:\n",
    "            # trata e exibe erros que ocorrerem durante a validação\n",
    "            print(f'Erro in cross validation. \\nErro: {error}')\n",
    "\n",
    "        print(\"Done.\")  # indica que finalizou o algoritmo atual\n",
    "\n",
    "    print(\"Assessment Completed\")  # mensagem final\n",
    "\n",
    "    # retorna os resultados como DataFrame\n",
    "    return pd.DataFrame.from_dict(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6c55ca",
   "metadata": {},
   "source": [
    "## -------------------- 10. Geração e Armazenamento dos Resultados com Validação Cruzada -------------------- \n",
    "\n",
    "Esta função realiza o pré-processamento do dataset, executa a avaliação dos algoritmos com validação cruzada e salva os resultados estatísticos (média ± desvio padrão) e o gráfico boxplot no diretório especificado. Ela faz parte da fase de avaliação e documentação dos resultados do pipeline de aprendizado de máquina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb803397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera boxplot e salva resultados do cross_val_score\n",
    "def generate_results(name, df, results_dir=results_dir):\n",
    "    print(f\"Generating Results for the Base {name}.\\n\")  # início da avaliação\n",
    "\n",
    "    df = convert_gender_to_numeric(df)  # type: ignore # converte 'gender' para valores numéricos\n",
    "    ycla = df.gender  # separa variável alvo\n",
    "    df = df.drop(\"gender\", axis=1)  # remove a coluna 'gender' dos atributos\n",
    "\n",
    "    start = timer()  # inicia a contagem de tempo\n",
    "    result = generate_cross_val_score_all_alg(df, ycla)  # roda a avaliação\n",
    "    time = timer() - start  # calcula tempo de execução\n",
    "\n",
    "    db_result_dir = 'results'  # define o diretório de saída\n",
    "    db_result_dir.mkdir(parents=True, exist_ok=True)  # cria o diretório se não existir\n",
    "\n",
    "    txt_dir = db_result_dir / f\"{name}.txt\"  # define o caminho do arquivo de texto\n",
    "    with open(txt_dir, 'w') as file:\n",
    "        # escreve média ± desvio padrão por algoritmo\n",
    "        file.write(result.apply(lambda x: \"{:.2f} ± {:.2f}\".format(x.mean(), x.std())).to_string())\n",
    "        file.write(f\"\\nExecution time: {time:.2f} seconds\")  # escreve o tempo total\n",
    "\n",
    "    # cria o gráfico boxplot com os resultados\n",
    "    plt.boxplot([scores for scores in result.values()])\n",
    "    plt.xticks(1 + np.arange(result.shape[1]), result.columns)\n",
    "    plot_file = db_result_dir / f\"{name}_boxplot.png\"  # define o nome do arquivo da imagem\n",
    "    plt.savefig(plot_file, dpi=300)  # salva a imagem\n",
    "    plt.close()  # fecha a figura\n",
    "\n",
    "    print(f\"Saved Information - Fit Time: {time:.2f}.\\n\")  # fim da execução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365a4049",
   "metadata": {},
   "source": [
    "## -------------------- 11. Funções Auxiliares de Avaliação e Visualização --------------------\n",
    "\n",
    "Este bloco define três funções auxiliares utilizadas durante a avaliação dos modelos: o cálculo das métricas (acurácia, precisão, recall e F1-score), a geração de gráficos boxplot dos resultados de validação cruzada e a visualização da matriz de confusão para cada experimento. Essas funções fazem parte da etapa de avaliação quantitativa e visual no pipeline de aprendizado de máquina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6384ed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula métricas de avaliação\n",
    "def generate_scores(y_test, y_pred):\n",
    "    return [\n",
    "        accuracy_score(y_test, y_pred),  # calcula acurácia\n",
    "        precision_score(y_test, y_pred, zero_division=0),  # calcula precisão\n",
    "        recall_score(y_test, y_pred, zero_division=0),  # calcula recall\n",
    "        f1_score(y_test, y_pred, zero_division=0)  # calcula f1-score\n",
    "    ]\n",
    "\n",
    "# Plota boxplot com os resultados de acurácia\n",
    "def plot_boxplot(result: dict, alg_name, boxplot_file, y_label_text=\"Score\"):\n",
    "    df_result = pd.DataFrame.from_dict(result)  # transforma o dicionário em DataFrame\n",
    "    \n",
    "    # Garante que o rótulo do eixo Y seja uma string\n",
    "    if not isinstance(y_label_text, str):\n",
    "        print(f\"Warning: y_label_text era {type(y_label_text)}. Convertendo.\")\n",
    "        y_label_text = str(y_label_text)\n",
    "\n",
    "    plt.style.use('default')  # aplica o estilo padrão do matplotlib\n",
    "    plt.figure(figsize=(8, 5))  # define o tamanho da figura\n",
    "    plt.boxplot([scores for scores in df_result.values.T])  # plota os boxplots\n",
    "    plt.title(\"Leave-One-Experiment-Out Boxplot\")  # título do gráfico\n",
    "    plt.ylabel(y_label_text)  # rótulo do eixo Y\n",
    "    plt.xticks(1 + np.arange(df_result.shape[1]), df_result.columns)  # define os rótulos no eixo X\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)  # adiciona grid para melhor legibilidade\n",
    "    plt.savefig(boxplot_file, dpi=300)  # salva a imagem no caminho especificado\n",
    "    plt.close()  # fecha o gráfico\n",
    "    print(f\"Boxplot salvo em: {boxplot_file}\")  # mensagem de confirmação\n",
    "\n",
    "# Plota a matriz de confusão para um experimento\n",
    "def plot_heatmap(Y_test, Y_pred, alg_name, db_result_dir, index):\n",
    "    cm = confusion_matrix(Y_test, Y_pred, labels=[0, 1])  # gera matriz de confusão 2x2\n",
    "\n",
    "    plt.figure(figsize=(10, 8))  # define o tamanho da figura\n",
    "    sns.heatmap(cm, xticklabels=[\"Women\", \"Men\"], yticklabels=[\"Women\", \"Men\"],\n",
    "                cmap=\"YlGnBu\", annot=True, fmt=\"d\")  # plota a matriz com cores e valores\n",
    "    sns.set(font_scale=1.1)  # ajusta o tamanho da fonte\n",
    "    plt.xlabel(\"Predicted Classes\")  # rótulo eixo X\n",
    "    plt.ylabel(\"True Classes\")  # rótulo eixo Y\n",
    "    plt.title(f\"Confusion Matrix - {alg_name}\")  # título do gráfico\n",
    "    plot_file = db_result_dir / f\"{alg_name}_confusion_matrix_experiment{index+1}.png\"  # caminho de saída\n",
    "    plt.savefig(plot_file, dpi=300)  # salva a imagem\n",
    "    plt.close()  # fecha o gráfico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a1ca1d",
   "metadata": {},
   "source": [
    "## -------------------- 12. Função para Formatação de Resultados Estatísticos --------------------\n",
    "\n",
    "Esta função auxilia na apresentação dos resultados, formatando a média e o desvio padrão de uma métrica de avaliação (como acurácia, precisão, etc.) em uma string padronizada. É utilizada na geração dos arquivos de saída para facilitar a leitura dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6a6d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formata string de média ± desvio padrão\n",
    "def format_string(valor, scores):\n",
    "    return f\"Mean {valor}: {np.mean(scores):.4f} ± {np.std(scores):.4f}\\n\"  # retorna string formatada com média e desvio padrão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bda09b",
   "metadata": {},
   "source": [
    "## -------------------- 13. Avaliação Leave-One-Experiment-Out (LOEO) para um Modelo -------------------- \n",
    "\n",
    "Esta função realiza a avaliação de um modelo usando a técnica Leave-One-Experiment-Out (LOEO), onde o conjunto de dados é dividido em 10 blocos (experimentos). Em cada iteração, um bloco é usado como teste e os demais como treino. Para cada rodada, o modelo é treinado, testado e suas métricas armazenadas. Ao final, gera gráficos, salva as métricas em arquivo e retorna os resultados consolidados. Esta etapa pertence à fase de avaliação robusta no pipeline de aprendizado de máquina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e1db376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação leave-one-experiment-out para um modelo\n",
    "def leave_one_experiment_out_evaluation(df, best_alg_name, results_dir, name):\n",
    "    print(f\"\\nStarting leave-one-experiment-out evaluation with the best model: {best_alg_name}\")  # início da avaliação\n",
    "\n",
    "    n_experimentos = 10  # total de blocos de experimentos\n",
    "    scores = {\"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1-Score\": []}  # dicionário para guardar métricas\n",
    "    y_true_all, y_pred_all = [], []  # listas para acumular rótulos reais e preditos\n",
    "\n",
    "    db_result_dir = results_dir / name  # define pasta de saída\n",
    "    db_result_dir.mkdir(parents=True, exist_ok=True)  # cria pasta se não existir\n",
    "    boxplot_file = db_result_dir / f\"{name}_leave_one_exp_boxplot.png\"  # caminho do gráfico final\n",
    "\n",
    "    # Configuração do StratifiedKFold para garantir balanceamento\n",
    "    skf = StratifiedKFold(n_splits=n_experimentos)\n",
    "    \n",
    "    # Convertendo dados uma única vez\n",
    "    df = convert_gender_to_numeric(df.copy())\n",
    "    X = df.drop(\"gender\", axis=1)\n",
    "    y = df[\"gender\"]\n",
    "    \n",
    "    # Loop sobre os folds estratificados\n",
    "    for i, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        print(f\"Processing experiment {i+1}/{n_experimentos}...\")\n",
    "        \n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        # Normalização dos dados\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        model = clone(algorithms[best_alg_name])  # clona o melhor modelo\n",
    "        model.fit(X_train, y_train)  # treina o modelo\n",
    "        y_pred = model.predict(X_test)  # realiza a predição\n",
    "\n",
    "        acc, precision, recall, f1 = generate_scores(y_test, y_pred)  # calcula métricas\n",
    "        scores[\"Accuracy\"].append(acc)  # armazena acurácia\n",
    "        scores[\"Precision\"].append(precision)  # armazena precisão\n",
    "        scores[\"Recall\"].append(recall)  # armazena recall\n",
    "        scores[\"F1-Score\"].append(f1)  # armazena f1-score\n",
    "\n",
    "        y_true_all.extend(y_test)  # acumula rótulos reais\n",
    "        y_pred_all.extend(y_pred)  # acumula predições\n",
    "\n",
    "        print(f\"Experiment {i+1}: Accuracy = {acc:.4f}\")  # exibe acurácia do experimento\n",
    "        plot_heatmap(y_test, y_pred, best_alg_name, db_result_dir, i)  # plota matriz de confusão\n",
    "\n",
    "    # Plota boxplot com as acurácias dos 10 experimentos\n",
    "    plot_boxplot({\"Accuracy\": scores[\"Accuracy\"]}, best_alg_name, boxplot_file, \"Accuracy\")\n",
    "\n",
    "    # Salva os resultados em arquivo de texto\n",
    "    txt_file = db_result_dir / f\"{name}_leave_one_exp_scores.txt\"\n",
    "    with open(txt_file, 'w') as f:\n",
    "        f.write(\"Accuracies leave-one-experiment-out:\\n\")\n",
    "        for i, score in enumerate(scores[\"Accuracy\"]):\n",
    "            f.write(f\"Experiment {i+1}: {score:.4f}\\n\")\n",
    "        for key, score in scores.items():\n",
    "            f.write(format_string(key, score))\n",
    "\n",
    "    print(f\"Scores saved in: {txt_file}\\n\")  # confirmação\n",
    "    return scores  # retorna o dicionário de métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9939ba13",
   "metadata": {},
   "source": [
    "## -------------------- 15. Avaliação Leave-One-Experiment-Out para Todos os Modelos --------------------\n",
    "\n",
    "Esta função executa a avaliação LOEO para todos os algoritmos definidos na configuração. Cada modelo é avaliado separadamente, e as acurácias de cada experimento são armazenadas. Ao final, um gráfico boxplot é gerado comparando os desempenhos entre os modelos. Esta etapa pertence à fase de comparação e análise de desempenho entre os classificadores no pipeline de aprendizado de máquina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82fc6e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executa avaliação leave-one-out para todos os modelos disponíveis\n",
    "def leave_one_experiment_out_evaluation_all_models(db_name):\n",
    "    print(\"\\nStarting leave-one-experiment-out evaluation for all models...\")\n",
    "    \n",
    "    acc_results = {}  # dicionário para guardar resultados de acurácia por modelo\n",
    "    results_df = pd.DataFrame()  # DataFrame para armazenar todos os resultados\n",
    "    \n",
    "    # Carrega os dados uma única vez\n",
    "    df = pd.read_csv(db_name)\n",
    "    \n",
    "    # Loop por todos os algoritmos\n",
    "    for i, alg_name in enumerate(algorithms.keys(), 1):\n",
    "        print(f\"\\nEvaluating model {alg_name} ({i}/{len(algorithms)})...\")\n",
    "        \n",
    "        # Gera nome para pasta/arquivos\n",
    "        name = Path(db_name).stem.replace(\".\", \"_\") + f\"_{alg_name}\"\n",
    "        \n",
    "        # Executa avaliação LOEO\n",
    "        scores = leave_one_experiment_out_evaluation(df, alg_name, results_dir, name)\n",
    "        \n",
    "        # Armazena resultados\n",
    "        acc_results[alg_name] = scores[\"Accuracy\"]\n",
    "        results_df[alg_name] = scores[\"Accuracy\"]\n",
    "        \n",
    "        # Salva resultados intermediários\n",
    "        results_df.to_csv(results_dir / \"loo_all_models_results.csv\")\n",
    "        print(f\"Intermediate results saved for {alg_name}\")\n",
    "\n",
    "    # Gera gráfico comparativo final\n",
    "    boxplot_file = results_dir / \"acc_boxplot_all_models.png\"\n",
    "    plot_boxplot(acc_results, \"All Models\", boxplot_file, \"Accuracy\")\n",
    "    \n",
    "    # Exibe resumo estatístico\n",
    "    print(\"\\nMean Accuracy by Model:\")\n",
    "    print(results_df.mean().sort_values(ascending=False))\n",
    "    \n",
    "    print(\"\\nLeave-one-experiment-out evaluation completed for all models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8ba178",
   "metadata": {},
   "source": [
    "## -------------------- 16. Execução Final da Avaliação para Todos os Modelos --------------------\n",
    "\n",
    "Este bloco define o caminho do dataset `.csv` e executa a função de avaliação Leave-One-Experiment-Out para todos os modelos disponíveis. Ao final, imprime os arquivos gerados na pasta `results/`, encerrando a fase principal de avaliação do pipeline de aprendizado de máquina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20291a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting leave-one-experiment-out evaluation for all models...\n",
      "\n",
      "Evaluating model kNN (1/6)...\n",
      "\n",
      "Starting leave-one-experiment-out evaluation with the best model: kNN\n",
      "Processing experiment 1/10...\n",
      "Experiment 1: Accuracy = 0.9969\n",
      "Processing experiment 2/10...\n",
      "Experiment 2: Accuracy = 0.9938\n",
      "Processing experiment 3/10...\n",
      "Experiment 3: Accuracy = 0.9938\n",
      "Processing experiment 4/10...\n",
      "Experiment 4: Accuracy = 1.0000\n",
      "Processing experiment 5/10...\n",
      "Experiment 5: Accuracy = 0.9844\n",
      "Processing experiment 6/10...\n",
      "Experiment 6: Accuracy = 0.9938\n",
      "Processing experiment 7/10...\n"
     ]
    }
   ],
   "source": [
    "# Executa a avaliação LOEO para todos os modelos\n",
    "leave_one_experiment_out_evaluation_all_models(arquivo_treino_validacao)\n",
    "\n",
    "# Lista os arquivos gerados na pasta de resultados\n",
    "print(\"\\nResults generated in:\")\n",
    "print([f for f in os.listdir('./results') if f.endswith(('.png', '.txt', '.csv'))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0250df",
   "metadata": {},
   "source": [
    "## -------------------- 17. Avaliação Final com Todos os Dados Usando o Melhor Modelo --------------------\n",
    "\n",
    "Esta etapa realiza a avaliação final do melhor modelo identificado pela média de acurácia na validação cruzada. O modelo é treinado com todos os dados disponíveis e, em seguida, avaliado no mesmo conjunto para fins descritivos. São geradas as métricas detalhadas (precisão, recall, f1-score e suporte) e a matriz de confusão final, que mostram como o modelo se comporta globalmente. A matriz é salva em `results/melhor_modelo_confusion_matrix_FINAL.png`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cf74f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Validação Cruzada Aninhada ===\n",
      "Acurácia Média: 0.9916 ± 0.0027\n",
      "\n",
      "Melhores parâmetros: {'criterion': 'gini', 'max_depth': 5}\n",
      "\n",
      "Relatório Final do Melhor Modelo (em todos os dados):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Women     0.9981    1.0000    0.9991      1600\n",
      "         Men     1.0000    0.9981    0.9991      1600\n",
      "\n",
      "    accuracy                         0.9991      3200\n",
      "   macro avg     0.9991    0.9991    0.9991      3200\n",
      "weighted avg     0.9991    0.9991    0.9991      3200\n",
      "\n",
      "Relatório salvo em: results/validacao_cruzada_aninhada.txt\n",
      "Matriz de confusão salva em: results/melhor_modelo_confusion_matrix_final.png\n"
     ]
    }
   ],
   "source": [
    "# ===================== CARREGAMENTO DOS DADOS =====================\n",
    "df = pd.read_csv(arquivo_treino_validacao)\n",
    "X = df.drop('gender', axis=1)\n",
    "y = df['gender']\n",
    "\n",
    "# ===================== CONFIGURAÇÃO DE VALIDAÇÃO =====================\n",
    "inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, None],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# ===================== GRID SEARCH ANINHADO =====================\n",
    "grid_search = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    param_grid,\n",
    "    cv=inner_cv,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "nested_scores = cross_val_score(grid_search, X=X, y=y, cv=outer_cv)\n",
    "\n",
    "print(\"=== Validação Cruzada Aninhada ===\")\n",
    "print(f\"Acurácia Média: {nested_scores.mean():.4f} ± {nested_scores.std():.4f}\")\n",
    "\n",
    "# ===================== TREINAMENTO FINAL =====================\n",
    "grid_search.fit(X, y)\n",
    "melhor_modelo = grid_search.best_estimator_\n",
    "print(f\"\\nMelhores parâmetros: {grid_search.best_params_}\")\n",
    "\n",
    "# ===================== RELATÓRIO FINAL =====================\n",
    "y_pred = melhor_modelo.predict(X)\n",
    "relatorio = classification_report(y, y_pred, target_names=[\"Women\", \"Men\"], digits=4)\n",
    "print(\"\\nRelatório Final do Melhor Modelo (em todos os dados):\")\n",
    "print(relatorio)\n",
    "\n",
    "# ===================== SALVA ARQUIVOS =====================\n",
    "Path(\"results\").mkdir(exist_ok=True)\n",
    "joblib.dump(melhor_modelo, 'results/melhor_modelo.pkl')\n",
    "\n",
    "with open(\"results/validacao_cruzada_aninhada.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"=== Validação Cruzada Aninhada ===\\n\")\n",
    "    f.write(f\"Acurácia Média: {nested_scores.mean():.4f} ± {nested_scores.std():.4f}\\n\\n\")\n",
    "    f.write(f\"Melhores Parâmetros: {grid_search.best_params_}\\n\\n\")\n",
    "    f.write(relatorio)\n",
    "print(\"Relatório salvo em: results/validacao_cruzada_aninhada.txt\")\n",
    "\n",
    "# ===================== MATRIZ DE CONFUSÃO =====================\n",
    "cm = confusion_matrix(y, y_pred, labels=[0, 1])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Women\", \"Men\"],\n",
    "            yticklabels=[\"Women\", \"Men\"])\n",
    "plt.xlabel(\"Classe Predita\")\n",
    "plt.ylabel(\"Classe Real\")\n",
    "titulo = f\"Matriz de Confusão - Melhor Modelo Final ({melhor_modelo.__class__.__name__})\"\n",
    "plt.title(titulo)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"results/melhor_modelo_confusion_matrix_final.png\", dpi=300)\n",
    "plt.close()\n",
    "print(\"Matriz de confusão salva em: results/melhor_modelo_confusion_matrix_final.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b16a40",
   "metadata": {},
   "source": [
    "## -------------------- 18. Comparação Visual entre Classificadores --------------------\n",
    "\n",
    "Adicionalmente, é gerado um gráfico com a comparação visual dos limites de decisão de vários algoritmos de classificação em datasets sintéticos. Esse gráfico ilustra a capacidade de generalização e a forma como cada modelo segmenta o espaço de decisão. Faz parte da etapa de análise comparativa/visualização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbf47b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Graph saved in: results/classifier_comparison.png\n"
     ]
    }
   ],
   "source": [
    "# Classificadores utilizados no projeto\n",
    "names = [\n",
    "    \"kNN\", \"Decision Tree\", \"Big Tree\", \"Naive Bayes\", \"SVM Linear\", \"SVM RBF\"\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),  # kNN\n",
    "    DecisionTreeClassifier(max_depth=5),  # Árvore pequena\n",
    "    DecisionTreeClassifier(),  # Árvore grande\n",
    "    GaussianNB(),  # Naive Bayes\n",
    "    SVC(kernel=\"linear\", C=0.025, probability=True),  # SVM Linear\n",
    "    SVC(gamma=2, C=1, probability=True),  # SVM RBF\n",
    "]\n",
    "\n",
    "# Datasets sintéticos para visualização\n",
    "datasets = [\n",
    "    make_moons(noise=0.3, random_state=0),\n",
    "    make_circles(noise=0.2, factor=0.5, random_state=1),\n",
    "    make_classification(\n",
    "        n_features=2, n_redundant=0, n_informative=2,\n",
    "        random_state=42, n_clusters_per_class=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Ignora avisos de convergência (MLP, etc)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "    # Cria figura com várias subplots\n",
    "    figure = plt.figure(figsize=(20, 6))\n",
    "    i = 1\n",
    "\n",
    "    for ds in datasets:\n",
    "        X, y = ds\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "        # Primeira coluna: dados originais\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        ax.set_title(\"Input data\")\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm, edgecolors='k')\n",
    "        i += 1\n",
    "\n",
    "        # Colunas seguintes: classificadores\n",
    "        for name, clf in zip(names, classifiers):\n",
    "            ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "            clf.fit(X_train, y_train)\n",
    "            score = clf.score(X_test, y_test)\n",
    "\n",
    "            # Exibe fronteira de decisão\n",
    "            display = DecisionBoundaryDisplay.from_estimator(\n",
    "                clf, X, response_method=\"predict\", cmap=plt.cm.coolwarm, alpha=0.8, ax=ax\n",
    "            )\n",
    "            ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=plt.cm.coolwarm, edgecolors='k')\n",
    "            ax.set_title(f\"{name}\\nAccuracy: {score:.2f}\")\n",
    "            i += 1\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"results/classifier_comparison.png\", dpi=300)\n",
    "    plt.close()\n",
    "    print(\"Comparison Graph saved in: results/classifier_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0830f9",
   "metadata": {},
   "source": [
    "## -------------------- 19. Geração da Árvore de Decisão Geral com Todos os Dados --------------------\n",
    "\n",
    "Este bloco treina uma árvore de decisão com todos os dados disponíveis e gera uma representação visual completa da estrutura da árvore. Esta etapa complementa a avaliação, permitindo uma interpretação visual do modelo final e das variáveis mais relevantes, sendo parte da explicação e apresentação de resultados do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda938eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Tree saved in: results/credit_tree_geral.png\n"
     ]
    }
   ],
   "source": [
    "# Garante que os dados estejam prontos\n",
    "df_full = convert_gender_to_numeric(df.copy())  # converte gênero para 0 e 1\n",
    "X = df_full.drop(\"gender\", axis=1)  # separa atributos\n",
    "y = df_full[\"gender\"]  # variável alvo\n",
    "\n",
    "# Treina o modelo completo com todos os dados\n",
    "modelo_geral = DecisionTreeClassifier(\n",
    "    max_depth=5,  # profundidade máxima da árvore\n",
    "    criterion='entropy',  # critério de divisão\n",
    "    random_state=42  # semente para reprodutibilidade\n",
    ")\n",
    "modelo_geral.fit(X, y)  # treina a árvore com todos os dados\n",
    "\n",
    "# Garante que a pasta 'results' exista\n",
    "Path(\"results\").mkdir(exist_ok=True)  # cria a pasta se não existir\n",
    "\n",
    "# Exporta a árvore para um arquivo .dot\n",
    "export_graphviz(\n",
    "    modelo_geral,\n",
    "    out_file=\"results/credit_tree_geral.dot\",  # caminho do arquivo de saída\n",
    "    feature_names=X.columns,  # nomes das variáveis\n",
    "    class_names=[\"Women\", \"Men\"],  # nomes das classes\n",
    "    rounded=True,  # cantos arredondados\n",
    "    filled=True  # cores nas folhas\n",
    ")\n",
    "\n",
    "# Renderiza o arquivo .dot e salva como .png\n",
    "graph = Source.from_file(\"results/credit_tree_geral.dot\")  # carrega o arquivo .dot\n",
    "graph.render(\"results/credit_tree_geral\", format=\"png\", cleanup=True)  # salva como imagem\n",
    "\n",
    "# Mensagem final de confirmação\n",
    "print(\"General Tree saved in: results/credit_tree_geral.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7fd3b9",
   "metadata": {},
   "source": [
    "## -------------------- 20. Curva ROC e Visualização PCA dos Dados --------------------\n",
    "\n",
    "Este bloco complementa a análise dos resultados com dois gráficos. Primeiro, a Curva ROC (Receiver Operating Characteristic), que mostra a performance do modelo ao variar o limiar de decisão, junto com o valor da AUC (Área sob a curva). Em seguida, um gráfico de dispersão usando PCA (Análise de Componentes Principais), reduzindo os dados para 2 dimensões e colorindo por gênero, permitindo visualizar possíveis separações entre as classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27ab6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Curve saved in: results/roc_curve.png\n",
      "PCA 2D Scatter saved in: results/pca_2d_scatter.png\n"
     ]
    }
   ],
   "source": [
    "# Função para plotar a curva ROC com AUC\n",
    "def plot_roc_curve(model, X_test, y_test, label=\"Modelo\"):\n",
    "    # Verifica se o modelo possui método predict_proba ou decision_function\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        probs = model.predict_proba(X_test)[:, 1]  # usa probabilidade da classe positiva\n",
    "    else:\n",
    "        probs = model.decision_function(X_test)  # usa função de decisão (ex: SVM)\n",
    "\n",
    "    # Calcula os valores de FPR (falsos positivos) e TPR (verdadeiros positivos)\n",
    "    fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "\n",
    "    # Calcula a área sob a curva (AUC)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # Cria o gráfico\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'{label} (AUC = {roc_auc:.2f})')  # curva principal\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # linha de referência (aleatório)\n",
    "    plt.xlabel('FPR (False Positives)')  # eixo X\n",
    "    plt.ylabel('TPR (True Positives)')  # eixo Y\n",
    "    plt.title('ROC Curve')  # título\n",
    "    plt.legend(loc=\"lower right\")  # legenda\n",
    "    plt.grid()  # adiciona grade\n",
    "    plt.savefig(\"results/roc_curve.png\", dpi=300)  # salva o gráfico\n",
    "    print(\"ROC Curve saved in: results/roc_curve.png\") \n",
    "    plt.close()  # fecha figura\n",
    "\n",
    "# Plota a curva ROC para o modelo geral\n",
    "plot_roc_curve(modelo_geral, X, y, label=\"General Tree\")\n",
    "\n",
    "# Reduz os dados para 2D com PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)  # aplica a transformação PCA\n",
    "\n",
    "# Converte rótulos numéricos para texto\n",
    "labels = y.map({0: 'Women', 1: 'Men'})\n",
    "\n",
    "# Cria gráfico de dispersão por gênero\n",
    "plt.figure(figsize=(8, 6))\n",
    "for label in labels.unique():\n",
    "    idx = labels == label\n",
    "    plt.scatter(X_pca[idx, 0], X_pca[idx, 1], label=label, alpha=0.7)  # plota cada grupo\n",
    "\n",
    "plt.title(\"PCA Dispersion by Gender - 8 subcarriers\")  # título do gráfico\n",
    "plt.xlabel(\"Principal Component 1\")  # eixo X\n",
    "plt.ylabel(\"Principal Component 2\")  # eixo Y\n",
    "plt.legend()  # exibe legenda\n",
    "plt.savefig(\"results/pca_2d_scatter.png\", dpi=300)  # salva o gráfico\n",
    "print(\"PCA 2D Scatter saved in: results/pca_2d_scatter.png\") \n",
    "plt.close()  # fecha a figura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d17cf2b",
   "metadata": {},
   "source": [
    "## -------------------- 21. PCA com Visualização Bidimensional (8 e 271 subportadoras) --------------------\n",
    "\n",
    "Essa etapa realiza uma redução de dimensionalidade via PCA para facilitar a visualização dos dados em 2D. São usados dois conjuntos diferentes (um com 271 subportadoras e outro com 8), permitindo comparação visual entre os gêneros após a transformação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc399aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA 271p: results/pca_271p.png\n",
      "PCA 8p: results/pca_8p.png\n"
     ]
    }
   ],
   "source": [
    "# === PCA - Visualização com 271 subportadoras ===\n",
    "\n",
    "df = pd.read_csv(arquivo_pca_271_portadoras)  # carrega o CSV como DataFrame\n",
    "\n",
    "y = df.iloc[:, 0]  # separa a variável alvo (0 = mulher, 1 = homem)\n",
    "X = df.iloc[:, 1:]  # separa os atributos (colunas de subportadoras)\n",
    "\n",
    "scaler = StandardScaler()  # instancia normalizador (zero média, variância 1)\n",
    "X_scaled = scaler.fit_transform(X)  # aplica normalização aos dados\n",
    "\n",
    "labels = y.map({0: 'Men', 1: 'Women'})  # converte rótulos numéricos em texto\n",
    "\n",
    "pca = PCA(n_components=2)  # define PCA com 2 componentes principais\n",
    "X_pca = pca.fit_transform(X_scaled)  # reduz os dados para 2D\n",
    "\n",
    "plt.figure(figsize=(8, 6))  # define tamanho da figura\n",
    "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1],\n",
    "                hue=y.map({0: 'Women', 1: 'Men'}), palette='Set1')  # cria gráfico colorido por gênero\n",
    "plt.title('PCA Dispersion by Gender - 271 subcarriers')  # título do gráfico\n",
    "plt.xlabel(\"Principal Component 1\")  # legenda eixo X\n",
    "plt.ylabel(\"Principal Component 2\")  # legenda eixo Y\n",
    "plt.legend()  # exibe legenda\n",
    "plt.grid(True)  # exibe grade no gráfico\n",
    "plt.tight_layout()  # ajusta margens\n",
    "plt.savefig(\"results/pca_271p.png\", dpi=300)  # salva a imagem no diretório\n",
    "print(\"PCA 271p: results/pca_271p.png\")\n",
    "plt.close()  # fecha a figura para liberar memória\n",
    "\n",
    "\n",
    "# === PCA - Visualização com 8 subportadoras ===\n",
    "\n",
    "df = pd.read_csv(arquivo_treino_validacao)  # carrega o CSV como DataFrame\n",
    "\n",
    "y = df.iloc[:, 0]  # variável alvo (0 = mulher, 1 = homem)\n",
    "X = df.iloc[:, 1:]  # atributos\n",
    "\n",
    "scaler = StandardScaler()  # normalizador padrão\n",
    "X_scaled = scaler.fit_transform(X)  # aplica normalização\n",
    "\n",
    "labels = y.map({0: 'Men', 1: 'Women'})  # transforma 0/1 em texto\n",
    "\n",
    "pca = PCA(n_components=2)  # PCA para 2 dimensões\n",
    "X_pca = pca.fit_transform(X_scaled)  # aplica a transformação PCA\n",
    "\n",
    "plt.figure(figsize=(8, 6))  # tamanho da figura\n",
    "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1],\n",
    "                hue=y.map({0: 'Women', 1: 'Men'}), palette='Set1')  # gráfico com cores por gênero\n",
    "plt.title('PCA Dispersion by Gender - 8 subcarriers')  # título do gráfico\n",
    "plt.xlabel(\"Principal Component 1\")  # eixo X\n",
    "plt.ylabel(\"Principal Component 2\")  # eixo Y\n",
    "plt.legend()  # legenda\n",
    "plt.grid(True)  # exibe grade\n",
    "plt.tight_layout()  # ajusta layout\n",
    "plt.savefig(\"results/pca_8p.png\", dpi=300)  # salva imagem no diretório results\n",
    "print(\"PCA 8p: results/pca_8p.png\")\n",
    "plt.close()  # fecha a figura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45eab53",
   "metadata": {},
   "source": [
    "## -------------------- 22. Relatório Final com Banco de Teste Real --------------------\n",
    "\n",
    "Esta etapa realiza a avaliação final do melhor modelo usando o conjunto de **teste real**.\n",
    "o modelo é treinado com **todo o conjunto de treino/validação** e testado contra os dados reais finais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6020f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Relatório de Classificação com Dados Reais:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Women     0.9797    0.9650    0.9723       400\n",
      "         Men     0.9655    0.9800    0.9727       400\n",
      "\n",
      "    accuracy                         0.9725       800\n",
      "   macro avg     0.9726    0.9725    0.9725       800\n",
      "weighted avg     0.9726    0.9725    0.9725       800\n",
      "\n",
      "Relatório salvo em: results/relatorio_teste_real.txt\n",
      "Real Test Confusion Matrix saved in: results/melhor_modelo_confusion_matrix_teste_real.png\n"
     ]
    }
   ],
   "source": [
    "# Carrega dados reais de teste\n",
    "df_teste_real = pd.read_csv(arquivo_teste_real)\n",
    "X_real = df_teste_real.drop('gender', axis=1)\n",
    "y_real = df_teste_real['gender']\n",
    "\n",
    "# Treina novamente o melhor modelo com 100% dos dados de treino/validação\n",
    "X_full = df.drop('gender', axis=1)\n",
    "y_full = df['gender']\n",
    "melhor_modelo.fit(X_full, y_full)\n",
    "\n",
    "# Predição no conjunto real\n",
    "y_pred_real = melhor_modelo.predict(X_real)\n",
    "\n",
    "# Geração do relatório\n",
    "relatorio_real = classification_report(y_real, y_pred_real, target_names=[\"Women\", \"Men\"], digits=4)\n",
    "\n",
    "# Exibe no terminal\n",
    "print(\"\\nRelatório de Classificação com Dados Reais:\")\n",
    "print(relatorio_real)\n",
    "\n",
    "# Salva em arquivo .txt\n",
    "Path(\"results\").mkdir(exist_ok=True)\n",
    "with open(\"results/relatorio_teste_real.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Relatório de Classificação com Dados Reais:\\n\\n\")\n",
    "    f.write(relatorio_real)\n",
    "print(\"Relatório salvo em: results/relatorio_teste_real.txt\")\n",
    "\n",
    "# Matriz de confusão\n",
    "cm_real = confusion_matrix(y_real, y_pred_real, labels=[0, 1])\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_real,\n",
    "            annot=True,\n",
    "            fmt=\"d\",\n",
    "            cmap=\"Blues\",\n",
    "            xticklabels=[\"Women\", \"Men\"],\n",
    "            yticklabels=[\"Women\", \"Men\"])\n",
    "plt.xlabel(\"Classe Predita\")\n",
    "plt.ylabel(\"Classe Real\")\n",
    "plt.title(f\"Matriz de Confusão - Teste Real ({melhor_modelo.__class__.__name__})\")\n",
    "\n",
    "# Salva imagem\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"results/melhor_modelo_confusion_matrix_teste_real.png\", dpi=300)\n",
    "plt.close()\n",
    "print(\"Real Test Confusion Matrix saved in: results/melhor_modelo_confusion_matrix_teste_real.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1258d96",
   "metadata": {},
   "source": [
    "## -------------------- Fim do código --------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
